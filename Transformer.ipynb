{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joel-Vijo/Neural-Machine-Translation/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DAJn8crQnXsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68168032-0fe2-47fd-b7b8-b0768102e14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.64.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchtext==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KccYlA3NECYS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import spacy\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "metadata": {
        "id": "jtUOBSR0juzk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "print(\"Notebook is running on\", device)\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZTviptjxBH",
        "outputId": "1755909c-11bd-49af-b84d-9b064bbe44ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook is running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de\n",
        "!python -m spacy download en\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBbzqy_Zj0_j",
        "outputId": "52aa59c2-ce21-499d-cccf-55fca9410cbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.3.0/de_core_news_sm-3.3.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 17.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 25.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "jOAipYRoj3Ia"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = Field(tokenize = tokenize_de, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            batch_first=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            batch_first=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1yFk8b1j5cA",
        "outputId": "cae13500-c3c8-4f5e-e713-93721f3a399c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG),root='data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4GS1aj0j8Wz",
        "outputId": "ea3ac109-07e9-4d61-d789-19bf413c3fa3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L9\\lok.j;k'\n",
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "metadata": {
        "id": "eRmqbTLbj_bC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class self_attention(nn.Module):\n",
        "  def __init__(self,input_dim,q_dim,k_dim,v_dim,heads):\n",
        "    super().__init__()\n",
        "    self.k_dim=k_dim\n",
        "    self.query=nn.Linear(input_dim,q_dim)\n",
        "    self.key=nn.Linear(input_dim,k_dim)\n",
        "    self.value=nn.Linear(input_dim,v_dim)\n",
        "    self.softmax=nn.Softmax()\n",
        "    self.head=heads\n",
        "    self.final=nn.Linear(q_dim,input_dim)\n",
        "  def forward(self,query,key,value,mask=None):\n",
        "    #print(\"Query\",query.size())\n",
        "    #print(\"Key\",key.size())\n",
        "    batch_size=query.shape[0]\n",
        "    q=self.query(query)\n",
        "    k=self.key(key)\n",
        "    v=self.value(value)\n",
        "    #print(q.size())\n",
        "    q=q.view(batch_size,-1,self.head,q.shape[2]//self.head).permute(0,2,1,3)\n",
        "    k=k.view(batch_size,-1,self.head,k.shape[2]//self.head).permute(0,2,1,3)\n",
        "    v=v.view(batch_size,-1,self.head,v.shape[2]//self.head).permute(0,2,1,3)\n",
        "    #print(\"Query2\",q.size())\n",
        "    #print(\"k\",k.size())\n",
        "    k=k.permute(0,1,3,2)\n",
        "    m=torch.matmul(q,k)\n",
        "    m=m/self.k_dim\n",
        "    #print(\"Mask\",mask.size())\n",
        "    #print(\"M\",m.size())\n",
        "\n",
        "    #mask=mask.permute(2,1,0)\n",
        "    if(mask is not None):\n",
        "      m=m.masked_fill(mask==0,-1e10)\n",
        "    #print(\"M\",m.size())\n",
        "    m=torch.softmax(m,dim=-1)\n",
        "    #print(\" v \",v.size())\n",
        "    z=torch.matmul(m,v)\n",
        "    z=z.permute(0,2,1,3).contiguous()\n",
        "    z=z.view(batch_size,-1,self.k_dim)\n",
        "    z=self.final(z)\n",
        "    return z\n",
        "\n"
      ],
      "metadata": {
        "id": "tP_p9Nc14QXB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class positional_feed_forward(nn.Module):\n",
        "  def __init__(self,input_dim,layer_dim):\n",
        "    super().__init__()\n",
        "    self.linear1=nn.Linear(input_dim,layer_dim)\n",
        "    self.linear2=nn.Linear(layer_dim,input_dim)\n",
        "    self.dropout=nn.Dropout(0.1)\n",
        "  def forward(self,input):\n",
        "    input=self.dropout(torch.relu(self.linear1(input)))\n",
        "    input=self.linear2(input)\n",
        "    return input"
      ],
      "metadata": {
        "id": "fznm-cL86nLS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_layer(nn.Module):\n",
        "  def __init__(self,input_dim,q_dim,v_dim,k_dim,pff_dim,heads):\n",
        "    super().__init__()\n",
        "    self.attention=self_attention(input_dim,q_dim,k_dim,v_dim,heads)\n",
        "    self.pff=positional_feed_forward(input_dim,pff_dim)\n",
        "    self.norm1=nn.LayerNorm(input_dim)\n",
        "    self.norm2=nn.LayerNorm(input_dim)\n",
        "  def forward(self,input,mask):\n",
        "    attention=self.attention(input,input,input,mask)\n",
        "    #print(\"Attention\",attention.size())\n",
        "    output=self.norm1(attention+input)\n",
        "    feed=self.pff(output)\n",
        "    #print(\"Output and feed\",output.size())\n",
        "    output=self.norm2(feed+output)\n",
        "    #print(\"Output\",output.size())\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "J2zzEgZCkLlV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dim,max_len,embedding_dim,q_dim,v_dim,k_dim,pff_dim,heads):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(input_dim,embedding_dim)\n",
        "    self.pos_embedding=nn.Embedding(max_len,embedding_dim)\n",
        "    self.layers=nn.ModuleList([Encoder_layer(embedding_dim,q_dim,v_dim,k_dim,pff_dim,heads) for i in range(3)])\n",
        "  def forward(self,input,mask):\n",
        "    pos_tensor=torch.arange(0,input.shape[1]).unsqueeze(0).repeat(input.shape[0],1).to(device)\n",
        "    embed=self.embedding(input)+self.pos_embedding(pos_tensor)\n",
        "    for layer in self.layers:\n",
        "      embed=layer(embed,mask)\n",
        "    return embed"
      ],
      "metadata": {
        "id": "5PwbKgDlVMQH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_layer(nn.Module):\n",
        "  def __init__(self,input_dim,q_dim,k_dim,v_dim,pff_dim,heads):\n",
        "    super().__init__()\n",
        "    self.attention1=self_attention(input_dim,q_dim,k_dim,v_dim,heads)\n",
        "    self.attention2=self_attention(input_dim,q_dim,k_dim,v_dim,heads)\n",
        "    self.pff=positional_feed_forward(input_dim,pff_dim)\n",
        "    self.norm1=nn.LayerNorm(input_dim)\n",
        "    self.norm2=nn.LayerNorm(input_dim)\n",
        "    self.norm3=nn.LayerNorm(input_dim)\n",
        "  def forward(self,input,enc_output,mask1,mask2):\n",
        "    #print(\"Decoder layer input\",input.size())\n",
        "    #print(\"Attention 1\")\n",
        "    attention1=self.attention1(input,input,input,mask1)\n",
        "    output=self.norm1(attention1+input)\n",
        "    #print(\"Encoder output\",enc_output.size())\n",
        "  \n",
        "    #print(\"Attention 2\")\n",
        "    attention2=self.attention2(output,enc_output,enc_output,mask2)\n",
        "    output=self.norm2(attention2+output)\n",
        "    feed=self.pff(output)\n",
        "    output=self.norm3(feed+output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "4k1pUYr-Y0r3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,input_dim,max_len,embedding_dim,q_dim,k_dim,v_dim,pff_dim,heads):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(input_dim,embedding_dim)\n",
        "    self.pos_embedding=nn.Embedding(max_len,embedding_dim)\n",
        "    self.linear=nn.Linear(embedding_dim,input_dim)\n",
        "    self.softmax=nn.Softmax(input_dim)\n",
        "    self.layers=nn.ModuleList([Decoder_layer(embedding_dim,q_dim,k_dim,v_dim,pff_dim,heads) for i in range(3)])\n",
        "  def forward(self,input,enc_output,mask1,mask2):\n",
        "    pos_tensor=torch.arange(0,input.shape[1]).unsqueeze(0).repeat(input.shape[0],1).to(device)\n",
        "    embed=self.embedding(input)+self.pos_embedding(pos_tensor)\n",
        "    for layer in self.layers:\n",
        "      #print(\"1\")\n",
        "      embed=layer(embed,enc_output,mask1,mask2)\n",
        "    output=self.linear(embed)\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "cYbWJyFd8MGv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,encoder,decoder,src_pad_ix,trg_pad_ix):\n",
        "    super().__init__()\n",
        "    self.enc=encoder\n",
        "    self.dec=decoder\n",
        "    self.src_pad=src_pad_ix\n",
        "    self.trg_pad=trg_pad_ix\n",
        "  def make_src_mask(self,m):\n",
        "    mask=(m!=self.src_pad).unsqueeze(1).unsqueeze(2)\n",
        "    return mask\n",
        "  def make_trg_mask(self,m):\n",
        "    mask=(m!=self.trg_pad).unsqueeze(1).unsqueeze(2)\n",
        "    len=m.shape[1]\n",
        "    sub_mask=torch.tril(torch.ones((len,len),device=device)).bool()\n",
        "    #print(\"MAIN MASK\",mask.size())\n",
        "    #print(\"SUB MASK\",sub_mask.size())\n",
        "    #mask=mask.permute(2,1,0)\n",
        "    mask=mask & sub_mask\n",
        "    #mask=mask.permute(2,1,0)\n",
        "    return mask\n",
        "  def forward(self,src,trg):\n",
        "    #print(\"SRC\",src.size())\n",
        "    src_mask=self.make_src_mask(src)\n",
        "    trg_mask=self.make_trg_mask(trg)\n",
        "    enc_outputs=self.enc(src,src_mask)\n",
        "    outputs=self.dec(trg,enc_outputs,trg_mask,src_mask)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "QcbkW_ZvMzXB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(SRC.vocab)\n",
        "output_dim=len(TRG.vocab)\n",
        "embedding_dim=256\n",
        "pf_dim=512\n",
        "heads=8\n",
        "max_len=100\n",
        "enc=Encoder(input_dim,max_len,embedding_dim,256,256,256,pf_dim,heads)\n",
        "dec=Decoder(output_dim,max_len,embedding_dim,256,256,256,pf_dim,heads)\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "model=Model(enc,dec,SRC_PAD_IDX,TRG_PAD_IDX).to(device)\n",
        "BATCH_SIZE=128\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,device=device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94bzF_ZbExq9",
        "outputId": "17e4b00b-374b-4626-969a-152d7615efe7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd3FU3XjTPsV",
        "outputId": "d78902ae-a2b9-4262-b8b0-998d0ce01a44"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,038,341 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "def train(model,iterator,criterion,optimiser):\n",
        "  model.train()\n",
        "  epoch_loss=0\n",
        "  for i,batch in enumerate(iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg    \n",
        "    optimizer.zero_grad()\n",
        "    #print(trg.size())\n",
        "    s=trg[1:,:].contiguous().view(-1)\n",
        "    #print(s.size())\n",
        "    output = model(src, trg[:,:-1])\n",
        "    #print(\"Output\",output.size())\n",
        "    #print(\"Finall output\",output.size())\n",
        "    #print(\"Trg\",trg.size())\n",
        "    #print(output)\n",
        "    output_size=output.shape[-1]\n",
        "    output=output.contiguous().view(-1,output_size)\n",
        "    trg=trg[:,1:].contiguous().view(-1)\n",
        "    #print(output.size())\n",
        "    #print(trg.size())\n",
        "    loss = criterion(output, trg)   \n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss/len(iterator)"
      ],
      "metadata": {
        "id": "ofXanxON1wY-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Evaluate(iterator, model, criterion):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for _, batch in enumerate(iterator):\n",
        "            source = batch.src\n",
        "            target = batch.trg\n",
        "            #print(target)\n",
        "            outputs = model(source, target[:,:-1])\n",
        "            #print(outputs)\n",
        "            #print(\"Trg\",trg.size())\n",
        "            output_size=outputs.shape[-1]\n",
        "            outputs=outputs.contiguous().view(-1,output_size)\n",
        "            target=target[:,1:].contiguous().view(-1)\n",
        "            batch_loss = criterion(outputs, target)\n",
        "            #print(outputs)\n",
        "            eval_loss += batch_loss.item()\n",
        "    return eval_loss/len(iterator)"
      ],
      "metadata": {
        "id": "Hm_-DertrUN3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  train_loss=train(model,train_iterator,criterion,optimizer)\n",
        "  valid_loss=Evaluate(valid_iterator,model,criterion)\n",
        "  print(\"Valid loss\",valid_loss)\n",
        "  print(\"  \")\n",
        "  print(\"TRAINING LOSS= \",train_loss)\n",
        "  print(\"  \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMpbWcq6kNs",
        "outputId": "a570c6b6-4a56-4f8f-ca1e-39ec01d4cd95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid loss 3.0734723806381226\n",
            "  \n",
            "TRAINING LOSS=  4.122138601042626\n",
            "  \n",
            "Valid loss 2.481746196746826\n",
            "  \n",
            "TRAINING LOSS=  2.87184216587554\n",
            "  \n",
            "Valid loss 2.1850149780511856\n",
            "  \n",
            "TRAINING LOSS=  2.3583249111007487\n",
            "  \n",
            "Valid loss 2.0122684985399246\n",
            "  \n",
            "TRAINING LOSS=  2.028018735578932\n",
            "  \n",
            "Valid loss 1.9131564944982529\n",
            "  \n",
            "TRAINING LOSS=  1.777159020764187\n",
            "  \n",
            "Valid loss 1.8293492496013641\n",
            "  \n",
            "TRAINING LOSS=  1.5744880821211222\n",
            "  \n",
            "Valid loss 1.8067896664142609\n",
            "  \n",
            "TRAINING LOSS=  1.3979041429343202\n",
            "  \n",
            "Valid loss 1.772386059165001\n",
            "  \n",
            "TRAINING LOSS=  1.2432931766636046\n",
            "  \n",
            "Valid loss 1.7795377969741821\n",
            "  \n",
            "TRAINING LOSS=  1.1058371915166074\n",
            "  \n",
            "Valid loss 1.7851138412952423\n",
            "  \n",
            "TRAINING LOSS=  0.9834409004266041\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss=Evaluate(test_iterator,model,criterion)\n",
        "print(test_loss)"
      ],
      "metadata": {
        "id": "8qtKxuqTsMfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402dc03c-4eca-4775-b307-8b384c62db29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8343684524297714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    model.eval()\n",
        "    print(sentence)\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    #print(src_tensor)\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.enc(src_tensor, src_mask)\n",
        "    print(\"Encoder output\",enc_src.size())\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "      \n",
        "        with torch.no_grad():\n",
        "            output = model.dec(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        #print(output)\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        print(pred_token)\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ],
      "metadata": {
        "id": "pPiTaEMNscpm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx=3\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "\n",
        "print(\"German:\",' '.join(src))\n",
        "print(\"English:\",' '.join(trg))\n",
        "print(\"Prediction:\",' '.join(translation[:-1]))"
      ],
      "metadata": {
        "id": "hemQ99BFtGN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ffa672-0ba2-4663-bf46-02f5943fa436"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fünf', 'leute', 'in', 'winterjacken', 'und', 'mit', 'helmen', 'stehen', 'im', 'schnee', 'mit', 'schneemobilen', 'im', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "251\n",
            "19\n",
            "22\n",
            "446\n",
            "555\n",
            "11\n",
            "628\n",
            "17\n",
            "36\n",
            "6\n",
            "7\n",
            "95\n",
            "13\n",
            "1577\n",
            "250\n",
            "5\n",
            "3\n",
            "German: fünf leute in winterjacken und mit helmen stehen im schnee mit schneemobilen im hintergrund .\n",
            "English: five people wearing winter jackets and helmets stand in the snow , with snowmobiles in the background .\n",
            "Prediction: five people wearing winter jackets and helmets are standing in the snow with pine trees .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "metadata": {
        "id": "ATkb7XkxtOR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55eac944-03fb-4bf0-8796-f97f947d7c73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fünf', 'leute', 'in', 'winterjacken', 'und', 'mit', 'helmen', 'stehen', 'im', 'schnee', 'mit', 'schneemobilen', 'im', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "251\n",
            "19\n",
            "22\n",
            "446\n",
            "555\n",
            "11\n",
            "628\n",
            "17\n",
            "36\n",
            "6\n",
            "7\n",
            "95\n",
            "13\n",
            "1577\n",
            "250\n",
            "5\n",
            "3\n",
            "predicted trg = ['five', 'people', 'wearing', 'winter', 'jackets', 'and', 'helmets', 'are', 'standing', 'in', 'the', 'snow', 'with', 'pine', 'trees', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmJrtSZ2uj5u",
        "outputId": "19df97a4-64ab-462d-931b-db46aa97ce71"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function bleu_score at 0x7f12ffcf9b90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "bleu= calculate_bleu(test_data, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu*100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LJK18ahsKci",
        "outputId": "9a297d51-1664-441b-a2dc-5303cb77dfc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "14\n",
            "36\n",
            "8\n",
            "4\n",
            "101\n",
            "39\n",
            "5\n",
            "3\n",
            "['feuerwehrmänner', 'kommen', 'aus', 'einer', 'u-bahnstation', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "1227\n",
            "0\n",
            "75\n",
            "12\n",
            "4\n",
            "354\n",
            "5\n",
            "3\n",
            "['vier', 'männer', ',', 'drei', 'von', 'ihnen', 'mit', 'gebetskappen', ',', 'sitzen', 'auf', 'einer', 'blau', 'und', 'olivgrün', 'gemusterten', 'matte', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "110\n",
            "30\n",
            "15\n",
            "48\n",
            "12\n",
            "155\n",
            "32\n",
            "8\n",
            "4\n",
            "444\n",
            "13\n",
            "29\n",
            "11\n",
            "620\n",
            "327\n",
            "543\n",
            "5\n",
            "3\n",
            "['das', 'ist', 'eine', 'große', 'menschengruppe', ',', 'die', 'im', 'freien', 'auf', 'bänken', 'sitzt', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "209\n",
            "10\n",
            "4\n",
            "59\n",
            "38\n",
            "12\n",
            "19\n",
            "32\n",
            "57\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'roten', 'shirt', 'geht', 'an', 'einem', 'türkis', 'und', 'weiß', 'karierten', 'imbissladen', 'namens', '\"', '32', 'de', 'neude', '\"', 'vorbei', '.']\n",
            "Encoder output torch.Size([1, 24, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "31\n",
            "23\n",
            "41\n",
            "232\n",
            "4\n",
            "384\n",
            "114\n",
            "136\n",
            "160\n",
            "0\n",
            "160\n",
            "0\n",
            "160\n",
            "0\n",
            "160\n",
            "5\n",
            "160\n",
            "5\n",
            "160\n",
            "5\n",
            "3\n",
            "['ärzte', 'bei', 'einer', 'art', 'operation', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "2476\n",
            "17\n",
            "186\n",
            "6\n",
            "4\n",
            "757\n",
            "5\n",
            "3\n",
            "['ein', 'älterer', 'mann', 'mit', 'einer', 'zigarette', 'im', 'mund', 'und', 'einer', 'mütze', 'inspiziert', 'seine', 'kamera', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "21\n",
            "115\n",
            "9\n",
            "13\n",
            "4\n",
            "516\n",
            "6\n",
            "27\n",
            "203\n",
            "11\n",
            "4\n",
            "67\n",
            "1788\n",
            "7\n",
            "116\n",
            "5\n",
            "3\n",
            "['kleines', 'orchester', 'spielt', 'im', 'freien', 'mit', 'einem', 'gitarrenkoffer', 'auf', 'dem', 'boden', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "24\n",
            "1202\n",
            "37\n",
            "57\n",
            "13\n",
            "4\n",
            "2335\n",
            "8\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'roten', 'anzug', 'tanzt', 'mit', 'einer', 'dame', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "31\n",
            "197\n",
            "10\n",
            "239\n",
            "13\n",
            "4\n",
            "120\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'betrachten', 'die', 'lichter', 'einer', 'stadt', 'bei', 'nacht', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "19\n",
            "56\n",
            "20\n",
            "7\n",
            "428\n",
            "12\n",
            "4\n",
            "101\n",
            "20\n",
            "305\n",
            "5\n",
            "3\n",
            "['zwei', 'motocrossfahrer', 'in', 'voller', 'schutzkleidung', ',', 'einer', 'von', 'ihnen', 'ist', 'nach', 'einem', 'sprung', 'in', 'der', 'luft', ',', 'der', 'andere', 'blickt', 'auf', 'sein', 'motorrad', 'hinunter', '.']\n",
            "Encoder output torch.Size([1, 27, 256])\n",
            "16\n",
            "1281\n",
            "1096\n",
            "15\n",
            "298\n",
            "1003\n",
            "15\n",
            "46\n",
            "10\n",
            "255\n",
            "7\n",
            "103\n",
            "15\n",
            "46\n",
            "10\n",
            "1142\n",
            "6\n",
            "445\n",
            "15\n",
            "7\n",
            "103\n",
            "15\n",
            "107\n",
            "8\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['mehrere', 'männer', 'in', 'orange', 'versammeln', 'sich', 'im', 'freien', 'für', 'ein', 'gesellschaftliches', 'ereignis', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "113\n",
            "30\n",
            "6\n",
            "86\n",
            "569\n",
            "57\n",
            "54\n",
            "4\n",
            "0\n",
            "358\n",
            "5\n",
            "3\n",
            "['zwei', 'junge', 'mädchen', 'rennen', 'auf', 'einem', 'gehsteig', 'vor', 'einem', 'ziegelgebäude', 'mit', 'plakaten', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "16\n",
            "24\n",
            "104\n",
            "79\n",
            "8\n",
            "4\n",
            "84\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "291\n",
            "77\n",
            "13\n",
            "4\n",
            "291\n",
            "77\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'klettern', 'einen', 'steilen', 'berg', 'hoch', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "16\n",
            "19\n",
            "230\n",
            "4\n",
            "1010\n",
            "221\n",
            "5\n",
            "3\n",
            "['ein', 'kind', 'liegt', 'auf', 'dem', 'boden', 'neben', 'einem', 'sportwagen', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "55\n",
            "273\n",
            "8\n",
            "7\n",
            "185\n",
            "71\n",
            "18\n",
            "4\n",
            "138\n",
            "5\n",
            "3\n",
            "['ein', 'hund', 'bettelt', 'bei', 'einem', 'mann', 'und', 'einer', 'frau', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "35\n",
            "10\n",
            "165\n",
            "4\n",
            "9\n",
            "11\n",
            "4\n",
            "14\n",
            "5\n",
            "3\n",
            "['viele', 'leute', 'auf', 'dem', 'markt', ',', 'die', 'verschiedene', 'dinge', 'betrachten', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "202\n",
            "19\n",
            "8\n",
            "7\n",
            "275\n",
            "395\n",
            "522\n",
            "2390\n",
            "5\n",
            "3\n",
            "['zwei', 'junge', 'männer', 'spielen', 'e-gitarren', 'auf', 'einer', 'bühne', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "16\n",
            "24\n",
            "30\n",
            "128\n",
            "8\n",
            "149\n",
            "5\n",
            "3\n",
            "['ein', 'tätowierter', 'mann', 'gießt', 'bier', 'aus', 'einer', 'flasche', 'in', 'den', 'mund', 'eines', 'jungen', 'mannes', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "1350\n",
            "9\n",
            "2356\n",
            "460\n",
            "75\n",
            "12\n",
            "4\n",
            "531\n",
            "12\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "26\n",
            "728\n",
            "81\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'stehen', 'draußen', 'neben', 'aufblasbaren', 'spielsachen', 'und', 'baggern', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "19\n",
            "17\n",
            "36\n",
            "57\n",
            "71\n",
            "18\n",
            "167\n",
            "72\n",
            "11\n",
            "0\n",
            "5\n",
            "3\n",
            "['vier', 'personen', 'fahren', 'rad', 'auf', 'einem', 'radweg', 'neben', 'einer', 'viel', 'befahrenen', 'straße', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "110\n",
            "19\n",
            "78\n",
            "99\n",
            "8\n",
            "4\n",
            "142\n",
            "71\n",
            "18\n",
            "4\n",
            "267\n",
            "39\n",
            "5\n",
            "3\n",
            "['frau', 'mit', 'brille', 'in', 'einem', 'pinken', 'hemd', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "14\n",
            "22\n",
            "146\n",
            "15\n",
            "22\n",
            "4\n",
            "90\n",
            "23\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'roten', 'shirt', 'hebt', 'ihren', 'arm', 'in', 'richtung', 'der', 'unten', 'vorbeiziehenden', 'menge', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "31\n",
            "23\n",
            "1518\n",
            "66\n",
            "394\n",
            "40\n",
            "7\n",
            "679\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'in', 'weißen', 'shorts', 'springt', 'in', 'einen', 'see', 'oder', 'einen', 'fluss', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "34\n",
            "6\n",
            "25\n",
            "148\n",
            "10\n",
            "92\n",
            "69\n",
            "4\n",
            "318\n",
            "258\n",
            "309\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'mädchen', 'blickt', 'durch', 'ein', 'teleskop', 'auf', 'den', 'strand', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "53\n",
            "33\n",
            "56\n",
            "60\n",
            "4\n",
            "859\n",
            "8\n",
            "7\n",
            "88\n",
            "5\n",
            "3\n",
            "['mehrere', 'bauarbeiter', 'in', 'orangen', 'sicherheitswesten', 'graben', 'im', 'boden', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "113\n",
            "216\n",
            "228\n",
            "22\n",
            "86\n",
            "561\n",
            "468\n",
            "786\n",
            "6\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['eine', 'person', 'mit', 'kapuze', 'steht', 'vor', 'einem', 'heruntergekommenen', 'gebäude', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "64\n",
            "22\n",
            "1234\n",
            "89\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "77\n",
            "5\n",
            "3\n",
            "['bauarbeiter', 'streiken', 'gegen', 'pm', 'construction', 'services', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "216\n",
            "228\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'auf', 'einem', 'rennpferd', 'mit', 'anderen', 'männern', 'auf', 'pferden', 'hinter', 'ihm', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "9\n",
            "8\n",
            "4\n",
            "923\n",
            "13\n",
            "82\n",
            "494\n",
            "93\n",
            "143\n",
            "5\n",
            "3\n",
            "['ein', 'afroamerikaner', 'geht', 'die', 'straße', 'hinunter', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "21\n",
            "324\n",
            "327\n",
            "9\n",
            "41\n",
            "40\n",
            "7\n",
            "39\n",
            "5\n",
            "3\n",
            "['zwei', 'nonnen', 'posieren', 'für', 'ein', 'foto', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "0\n",
            "249\n",
            "54\n",
            "4\n",
            "134\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'mit', 'neonfarbenen', 'kopfhörern', 'schreibt', 'in', 'einen', 'block', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "14\n",
            "13\n",
            "4\n",
            "375\n",
            "738\n",
            "10\n",
            "680\n",
            "6\n",
            "4\n",
            "997\n",
            "912\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'grün', 'gemusterten', 'hemd', 'telefoniert', 'mit', 'dem', 'handy', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "52\n",
            "1806\n",
            "1806\n",
            "23\n",
            "119\n",
            "8\n",
            "7\n",
            "349\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'afrikanisches', 'kind', 'trägt', 'ein', 'jüngeres', 'kind', 'auf', 'dem', 'rücken', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "24\n",
            "55\n",
            "10\n",
            "151\n",
            "4\n",
            "55\n",
            "8\n",
            "7\n",
            "182\n",
            "12\n",
            "4\n",
            "55\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'leuten', ',', 'die', 'auf', 'stühlen', 'sitzen', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "32\n",
            "6\n",
            "401\n",
            "5\n",
            "3\n",
            "['eine', 'mann', 'mit', 'einem', 'kopftuch', 'steht', 'auf', 'der', 'straße', 'vor', 'seinen', 'sachen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "9\n",
            "22\n",
            "4\n",
            "501\n",
            "89\n",
            "8\n",
            "7\n",
            "39\n",
            "6\n",
            "43\n",
            "12\n",
            "27\n",
            "138\n",
            "5\n",
            "3\n",
            "['eine', 'person', 'orientalischen', 'aussehens', 'in', 'einem', 'roten', 'shirt', 'und', 'schwarzer', 'hose', 'hockt', 'über', 'einer', 'handtasche', 'auf', 'dem', 'beton', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "4\n",
            "64\n",
            "10\n",
            "0\n",
            "4\n",
            "31\n",
            "23\n",
            "15\n",
            "11\n",
            "4\n",
            "31\n",
            "23\n",
            "15\n",
            "11\n",
            "147\n",
            "15\n",
            "1394\n",
            "76\n",
            "4\n",
            "434\n",
            "959\n",
            "5\n",
            "3\n",
            "['ein', 'schwarzer', 'und', 'ein', 'brauner', 'hund', 'mit', 'einem', 'ball', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "26\n",
            "11\n",
            "61\n",
            "35\n",
            "13\n",
            "4\n",
            "68\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'einer', 'schwarzen', 'weste', 'hält', 'ein', 'modellflugzeug']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "45\n",
            "4\n",
            "26\n",
            "339\n",
            "10\n",
            "45\n",
            "4\n",
            "1237\n",
            "1016\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'auf', 'einem', 'feld', 'mit', 'einem', 'flugzeug', 'in', 'sicht', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "8\n",
            "4\n",
            "85\n",
            "13\n",
            "21\n",
            "1016\n",
            "6\n",
            "21\n",
            "1016\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'anzug', 'mit', 'krawatte', 'und', 'eine', 'frau', 'mit', 'gepäck', 'gesellen', 'sich', 'zu', 'anderen', 'wartenden', 'in', 'der', 'londoner', 'u-bahn', '.']\n",
            "Encoder output torch.Size([1, 24, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "197\n",
            "13\n",
            "4\n",
            "640\n",
            "11\n",
            "14\n",
            "6\n",
            "4\n",
            "1029\n",
            "912\n",
            "18\n",
            "389\n",
            "426\n",
            "5\n",
            "3\n",
            "['ein', 'kind', 'geht', 'auf', 'dem', 'gehsteig', 'und', 'trägt', 'ein', 'paar', 'amerikanische', 'flaggen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "55\n",
            "41\n",
            "8\n",
            "7\n",
            "84\n",
            "151\n",
            "4\n",
            "485\n",
            "543\n",
            "5\n",
            "3\n",
            "['ein', 'schwarzer', 'hund', 'läuft', 'auf', 'grünem', 'gras', 'mit', 'einem', 'spielzeug', 'im', 'maul', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "26\n",
            "35\n",
            "10\n",
            "79\n",
            "8\n",
            "52\n",
            "96\n",
            "6\n",
            "7\n",
            "96\n",
            "5\n",
            "3\n",
            "['ein', 'orientalischer', 'reisender', 'wartet', 'am', 'wechselschalter', 'bis', 'er', 'dran', 'ist', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "937\n",
            "0\n",
            "10\n",
            "254\n",
            "54\n",
            "7\n",
            "0\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'hund', 'dreht', 'sich', 'auf', 'dem', 'gras', 'um', 'einem', 'fliegenden', 'ball', 'nachzulaufen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "35\n",
            "1602\n",
            "18\n",
            "128\n",
            "7\n",
            "68\n",
            "8\n",
            "7\n",
            "96\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'studenten', 'sitzt', 'und', 'hört', 'der', 'sprecherin', 'zu', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "521\n",
            "17\n",
            "32\n",
            "11\n",
            "577\n",
            "18\n",
            "7\n",
            "0\n",
            "5\n",
            "3\n",
            "['menschen', 'fahren', 'bei', 'nacht', 'mit', 'mopeds', 'die', 'straße', 'hinunter', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "19\n",
            "17\n",
            "78\n",
            "66\n",
            "305\n",
            "40\n",
            "7\n",
            "39\n",
            "20\n",
            "305\n",
            "5\n",
            "3\n",
            "['ein', 'großes', ',', 'graues', 'seedeck', 'und', 'ein', 'typ', 'auf', 'dem', 'fahrrad', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "59\n",
            "132\n",
            "15\n",
            "161\n",
            "15\n",
            "11\n",
            "4\n",
            "174\n",
            "78\n",
            "4\n",
            "157\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'orangen', 'shirt', 'und', 'ein', 'blonder', 'junge', 'fahren', 'mit', 'anderen', 'personen', 'in', 'einem', '\"', 'pullman', '\"', '.']\n",
            "Encoder output torch.Size([1, 22, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "21\n",
            "86\n",
            "23\n",
            "11\n",
            "4\n",
            "122\n",
            "34\n",
            "78\n",
            "4\n",
            "99\n",
            "13\n",
            "72\n",
            "1110\n",
            "6\n",
            "7\n",
            "72\n",
            "5\n",
            "3\n",
            "['ein', 'junger', 'mann', 'und', 'frauen', 'nahe', 'einer', 'großen', 'metallskulptur']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "11\n",
            "50\n",
            "17\n",
            "80\n",
            "4\n",
            "59\n",
            "307\n",
            "520\n",
            "5\n",
            "3\n",
            "['ein', 'boot', 'mit', 'roten', ',', 'weißen', 'und', 'blauen', 'segeln', 'dockt', 'an', 'einem', 'pier', 'an', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "180\n",
            "13\n",
            "31\n",
            "15\n",
            "25\n",
            "15\n",
            "11\n",
            "29\n",
            "0\n",
            "10\n",
            "1734\n",
            "8\n",
            "4\n",
            "856\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'einer', 'schwarzen', 'mütze', 'macht', 'ein', 'foto', 'auf', 'einer', 'belebten', 'straße', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "26\n",
            "283\n",
            "10\n",
            "165\n",
            "4\n",
            "342\n",
            "8\n",
            "4\n",
            "267\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'steht', 'auf', 'einer', 'belebten', 'straße', 'und', 'sieht', 'sich', 'mit', 'in', 'den', 'nacken', 'gelegten', 'kopf', 'um', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "36\n",
            "8\n",
            "4\n",
            "267\n",
            "39\n",
            "56\n",
            "40\n",
            "13\n",
            "44\n",
            "172\n",
            "6\n",
            "44\n",
            "172\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'schwarz', 'trägt', 'ein', 'kleines', 'mädchen', 'in', 'einem', 'gelben', 'kleid', 'auf', 'ihren', 'schultern', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "26\n",
            "10\n",
            "151\n",
            "4\n",
            "53\n",
            "33\n",
            "6\n",
            "4\n",
            "62\n",
            "117\n",
            "8\n",
            "44\n",
            "876\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'menschen', 'baut', 'auf', 'der', 'straße', 'instrumente', 'auf', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "17\n",
            "77\n",
            "8\n",
            "7\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'offroad-biker', 'hilft', 'einem', 'anderen', ',', 'der', 'hingefallen', 'ist', ',', 'auf', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "34\n",
            "1373\n",
            "285\n",
            "189\n",
            "10\n",
            "41\n",
            "13\n",
            "82\n",
            "5\n",
            "3\n",
            "['drei', 'personen', 'gehen', 'einen', 'gebirgspfad', 'hoch', ',', 'eine', 'davon', 'blickt', 'auf', 'ihre', 'kamera', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "48\n",
            "19\n",
            "17\n",
            "41\n",
            "51\n",
            "4\n",
            "661\n",
            "56\n",
            "51\n",
            "58\n",
            "4\n",
            "116\n",
            "5\n",
            "3\n",
            "['mehrere', 'asiatische', 'männer', 'in', 'schwarzer', 'kleidung', 'in', 'einer', 'art', 'station', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "113\n",
            "106\n",
            "30\n",
            "73\n",
            "6\n",
            "26\n",
            "15\n",
            "186\n",
            "74\n",
            "958\n",
            "12\n",
            "1863\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'roten', 'rock', 'geht', 'auf', 'der', 'straße', 'mit', 'graffiti', 'im', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "31\n",
            "451\n",
            "10\n",
            "41\n",
            "8\n",
            "7\n",
            "39\n",
            "13\n",
            "4\n",
            "390\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['eine', 'rhythmische', 'sportgymnastin', 'in', 'einem', 'blauen', 'und', 'pinken', 'outfit', 'vollführt', 'eine', 'bewegung', 'mit', 'dem', 'band', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "183\n",
            "213\n",
            "105\n",
            "22\n",
            "4\n",
            "29\n",
            "11\n",
            "26\n",
            "300\n",
            "10\n",
            "186\n",
            "4\n",
            "838\n",
            "8\n",
            "7\n",
            "149\n",
            "5\n",
            "3\n",
            "['leute', ',', 'die', 'sich', 'in', 'einem', 'springbrunnen', 'abkühlen', ',', 'eine', 'frau', 'in', 'einem', 'weißen', 'kleid', 'sitzt', 'am', 'rand', 'und', 'sieht', 'zu', '.']\n",
            "Encoder output torch.Size([1, 24, 256])\n",
            "19\n",
            "32\n",
            "6\n",
            "4\n",
            "2035\n",
            "177\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "25\n",
            "117\n",
            "10\n",
            "32\n",
            "8\n",
            "7\n",
            "84\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'sitzt', 'auf', 'einer', 'bank', 'unter', 'einem', 'großen', 'baum', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "91\n",
            "8\n",
            "4\n",
            "144\n",
            "863\n",
            "4\n",
            "59\n",
            "159\n",
            "5\n",
            "3\n",
            "['drei', 'männer', 'in', 'rot', 'und', 'weiß', 'gestreiften', 'shirts', ',', 'weißen', 'hosen', 'und', 'mit', 'schwarzen', 'hüten', 'halten', 'flaggen', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "48\n",
            "30\n",
            "22\n",
            "31\n",
            "15\n",
            "25\n",
            "11\n",
            "25\n",
            "15\n",
            "25\n",
            "15\n",
            "163\n",
            "15\n",
            "11\n",
            "26\n",
            "147\n",
            "15\n",
            "13\n",
            "26\n",
            "279\n",
            "5\n",
            "3\n",
            "['leute', 'bewundern', 'ein', 'kunstwerk', '.']\n",
            "Encoder output torch.Size([1, 7, 256])\n",
            "19\n",
            "17\n",
            "2133\n",
            "4\n",
            "315\n",
            "12\n",
            "511\n",
            "5\n",
            "3\n",
            "['geschäftiges', 'asiatisches', 'einkaufszentrum', 'mit', 'papierlaternen', 'und', 'einkäufern', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "106\n",
            "50\n",
            "17\n",
            "332\n",
            "13\n",
            "0\n",
            "11\n",
            "0\n",
            "5\n",
            "3\n",
            "['diese', 'personen', 'klettern', 'die', 'stufen', 'zum', 'berg', 'hoch']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "860\n",
            "19\n",
            "17\n",
            "230\n",
            "51\n",
            "7\n",
            "221\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'kind', 'in', 'blau', 'sieht', 'zu', 'bäumen', ',', 'die', 'in', 'der', 'ferne', 'stehen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "24\n",
            "55\n",
            "6\n",
            "29\n",
            "107\n",
            "8\n",
            "58\n",
            "7\n",
            "452\n",
            "6\n",
            "7\n",
            "452\n",
            "5\n",
            "3\n",
            "['leute', 'betrachten', 'kinderspielzeug', 'in', 'einem', 'geschäft', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "19\n",
            "56\n",
            "20\n",
            "7\n",
            "207\n",
            "6\n",
            "4\n",
            "207\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'hut', 'spielt', 'auf', 'der', 'straße', 'schlagzeug', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "67\n",
            "10\n",
            "37\n",
            "7\n",
            "534\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'steht', 'mit', 'drei', 'mädchen', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "4\n",
            "34\n",
            "89\n",
            "13\n",
            "48\n",
            "104\n",
            "5\n",
            "3\n",
            "['ein', 'lächelnder', 'mann', 'mit', 'rucksack', 'streckt', 'vor', 'einem', 'jungen', 'mit', 'brille', 'die', 'fäuste', 'in', 'die', 'luft', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "133\n",
            "9\n",
            "13\n",
            "4\n",
            "343\n",
            "6\n",
            "43\n",
            "12\n",
            "146\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "34\n",
            "22\n",
            "146\n",
            "5\n",
            "3\n",
            "['vier', 'männer', 'sind', 'im', 'freien', 'und', 'blicken', 'von', 'der', 'grünen', 'brücke', ',', 'auf', 'der', 'sie', 'stehen', ',', 'hinunter', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "110\n",
            "30\n",
            "17\n",
            "57\n",
            "56\n",
            "20\n",
            "305\n",
            "15\n",
            "52\n",
            "15\n",
            "36\n",
            "8\n",
            "7\n",
            "52\n",
            "378\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'entspannt', 'vor', 'leuten', ',', 'die', 'das', 'blaue', 'wasser', 'genießen', ',', 'auf', 'einem', 'handtuch', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "14\n",
            "790\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "29\n",
            "431\n",
            "243\n",
            "304\n",
            "4\n",
            "1177\n",
            "5\n",
            "3\n",
            "['ein', 'ausgewachsener', 'australian', 'shepherd', 'folgt', 'einem', 'welpen', ',', 'der', 'vor', 'ihm', 'läuft', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "0\n",
            "35\n",
            "1492\n",
            "4\n",
            "632\n",
            "1387\n",
            "15\n",
            "13\n",
            "4\n",
            "1387\n",
            "212\n",
            "6\n",
            "43\n",
            "12\n",
            "143\n",
            "5\n",
            "3\n",
            "['herbsteinkäufer', 'und', 'bistroliebhaber', 'lassen', 'sich', 'in', 'den', 'gezeiten', 'der', 'stadt', 'treiben', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "0\n",
            "11\n",
            "0\n",
            "17\n",
            "617\n",
            "6\n",
            "7\n",
            "101\n",
            "2590\n",
            "5\n",
            "3\n",
            "['der', 'afroamerikaner', 'protestiert', 'gegen', 'gesetzwidrigen', 'sex', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "7\n",
            "324\n",
            "327\n",
            "9\n",
            "1581\n",
            "1581\n",
            "7\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'polizist', 'sitzt', 'auf', 'dem', 'motorrad', 'und', 'wartet', ',', 'bis', 'die', 'ampel', 'auf', 'grün', 'springt', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "362\n",
            "705\n",
            "91\n",
            "8\n",
            "7\n",
            "295\n",
            "254\n",
            "54\n",
            "7\n",
            "52\n",
            "58\n",
            "205\n",
            "179\n",
            "8\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'männern', 'sitzt', 'an', 'einem', 'tisch', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "30\n",
            "32\n",
            "20\n",
            "4\n",
            "94\n",
            "5\n",
            "3\n",
            "['gruppe', 'hochrangiger', 'geschäftsleute', ',', 'darunter', 'auch', 'ältere', 'personen', ',', 'nehmen', 'in', 'einem', 'park', 'drinks', 'zu', 'sich', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "38\n",
            "12\n",
            "0\n",
            "871\n",
            "131\n",
            "17\n",
            "252\n",
            "4\n",
            "566\n",
            "28\n",
            "304\n",
            "877\n",
            "5\n",
            "3\n",
            "['frau', 'spricht', 'mit', 'freundin', 'während', 'spaziergangs', 'mit', 'hund', 'im', 'freien', 'an', 'einem', 'sonnigen', 'tag', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "14\n",
            "119\n",
            "8\n",
            "4\n",
            "0\n",
            "35\n",
            "57\n",
            "13\n",
            "4\n",
            "35\n",
            "8\n",
            "4\n",
            "396\n",
            "184\n",
            "5\n",
            "3\n",
            "['ein', 'junger', 'mann', 'in', 'einem', 'schwarz-weißen', 'shirt', 'und', 'weißem', 'stirnband', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "6\n",
            "4\n",
            "26\n",
            "11\n",
            "25\n",
            "23\n",
            "11\n",
            "25\n",
            "1557\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'fahren', 'motorrad', 'gemeinsam', 'mit', 'vielen', 'anderen', 'motorradfahrern', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "19\n",
            "78\n",
            "1092\n",
            "129\n",
            "13\n",
            "202\n",
            "72\n",
            "19\n",
            "5\n",
            "3\n",
            "['zwei', 'frauen', 'in', 'militäruniformen', 'stehen', 'mit', 'anderen', 'soldaten', 'in', 'formation', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "16\n",
            "50\n",
            "6\n",
            "602\n",
            "338\n",
            "100\n",
            "13\n",
            "72\n",
            "19\n",
            "5\n",
            "3\n",
            "['drei', 'mädchen', 'lächeln', 'für', 'ein', 'foto', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "48\n",
            "104\n",
            "133\n",
            "54\n",
            "4\n",
            "134\n",
            "5\n",
            "3\n",
            "['die', 'dame', 'mit', 'der', 'schwarz', 'gerahmten', 'brille', 'und', 'der', 'gelben', 'sweatjacke', 'blickt', 'verwirrt', 'während', 'sie', 'auf', 'der', 'braunen', 'bank', 'sitzt', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "7\n",
            "120\n",
            "22\n",
            "4\n",
            "26\n",
            "386\n",
            "26\n",
            "146\n",
            "11\n",
            "62\n",
            "146\n",
            "10\n",
            "56\n",
            "20\n",
            "7\n",
            "39\n",
            "28\n",
            "32\n",
            "8\n",
            "7\n",
            "144\n",
            "5\n",
            "3\n",
            "['ein', 'rothaariger', 'junger', 'mann', 'trinkt', 'aus', 'einem', 'springbrunnen', ',', 'der', 'wie', 'eine', 'frau', 'geformt', 'ist', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "24\n",
            "31\n",
            "42\n",
            "210\n",
            "9\n",
            "599\n",
            "65\n",
            "4\n",
            "383\n",
            "13\n",
            "4\n",
            "14\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'und', 'eine', 'frau', 'gehen', 'eine', 'straße', 'in', 'einer', 'stadt', 'entlang', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "16\n",
            "30\n",
            "11\n",
            "4\n",
            "14\n",
            "41\n",
            "40\n",
            "4\n",
            "101\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mittleren', 'alters', 'mit', 'roten', 'haaren', 'und', 'brille', 'hält', 'einen', 'säugling', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "168\n",
            "42\n",
            "433\n",
            "9\n",
            "13\n",
            "31\n",
            "146\n",
            "11\n",
            "45\n",
            "4\n",
            "887\n",
            "5\n",
            "3\n",
            "['ein', 'kleiner', 'junge', 'mit', 'roter', 'mütze', 'reitet', 'auf', 'einem', 'pferd', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "53\n",
            "34\n",
            "6\n",
            "4\n",
            "31\n",
            "67\n",
            "241\n",
            "4\n",
            "198\n",
            "5\n",
            "3\n",
            "['zwei', 'jungen', 'spielen', 'auf', 'dem', 'gehsteig', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "127\n",
            "17\n",
            "37\n",
            "8\n",
            "7\n",
            "84\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'mädchen', 'in', 'einem', 'schwarzen', 'badeanzug', 'hält', 'eine', 'schaufel', 'am', 'strand', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "53\n",
            "33\n",
            "6\n",
            "4\n",
            "26\n",
            "541\n",
            "197\n",
            "10\n",
            "45\n",
            "4\n",
            "805\n",
            "8\n",
            "7\n",
            "88\n",
            "5\n",
            "3\n",
            "['alter', 'mann', 'mit', 'hut', 'und', 'mantel', 'schläft', 'im', 'sitzen', 'auf', 'einem', 'sofa', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "145\n",
            "9\n",
            "22\n",
            "4\n",
            "67\n",
            "11\n",
            "193\n",
            "822\n",
            "8\n",
            "4\n",
            "425\n",
            "5\n",
            "3\n",
            "['zwei', 'jungen', 'in', 'winterkleidung', 'sehen', 'zum', 'himmel', 'hoch', 'und', 'winken', 'mit', 'den', 'armen', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "16\n",
            "127\n",
            "73\n",
            "6\n",
            "446\n",
            "219\n",
            "214\n",
            "51\n",
            "18\n",
            "7\n",
            "464\n",
            "13\n",
            "66\n",
            "181\n",
            "51\n",
            "5\n",
            "3\n",
            "['ein', 'junges', 'paar', 'sitzt', 'auf', 'dem', 'gehsteig', 'und', 'entspannt', 'gemeinsam', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "24\n",
            "154\n",
            "91\n",
            "8\n",
            "7\n",
            "84\n",
            "790\n",
            "5\n",
            "3\n",
            "['ein', 'jugendlicher', 'in', 'hemd', 'und', 'krawatte', 'kniet', 'und', 'macht', 'ein', 'peace-zeichen', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "1012\n",
            "6\n",
            "4\n",
            "23\n",
            "11\n",
            "640\n",
            "671\n",
            "165\n",
            "4\n",
            "1286\n",
            "206\n",
            "5\n",
            "3\n",
            "['drei', 'personen', 'sitzen', 'an', 'einem', 'tisch', 'vor', 'der', 'bar', 'gelati', 'tabacchi', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "48\n",
            "19\n",
            "32\n",
            "20\n",
            "4\n",
            "94\n",
            "6\n",
            "43\n",
            "12\n",
            "0\n",
            "379\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'in', 'einem', 'schwarzen', 'shirt', 'und', 'mit', 'roten', 'schweißbändern', 'hängt', 'kopfüber', 'während', 'andere', 'leute', 'zusehen', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "34\n",
            "6\n",
            "4\n",
            "26\n",
            "23\n",
            "13\n",
            "4\n",
            "31\n",
            "23\n",
            "1025\n",
            "808\n",
            "40\n",
            "28\n",
            "72\n",
            "19\n",
            "201\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'geht', 'vor', 'einem', 'bunten', 'wandgemälde', 'vorbei', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "41\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "263\n",
            "263\n",
            "891\n",
            "5\n",
            "3\n",
            "['ein', 'junger', 'mann', ',', 'der', 'mit', 'einem', 'weiteren', 'jungen', 'mann', 'unterwegs', 'ist', ',', 'blickt', 'sich', 'nach', 'drei', 'mädchen', 'um', ',', 'an', 'denen', 'sie', 'gerade', 'vorbeigegangen', 'sind', '.']\n",
            "Encoder output torch.Size([1, 29, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "56\n",
            "20\n",
            "7\n",
            "72\n",
            "127\n",
            "56\n",
            "20\n",
            "4\n",
            "24\n",
            "9\n",
            "56\n",
            "18\n",
            "414\n",
            "454\n",
            "414\n",
            "454\n",
            "18\n",
            "414\n",
            "454\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'schneidet', 'in', 'einem', 'gartenähnlichen', 'café', 'eine', 'palme', 'zurück', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "466\n",
            "4\n",
            "0\n",
            "6\n",
            "4\n",
            "0\n",
            "437\n",
            "18\n",
            "21\n",
            "2321\n",
            "5\n",
            "3\n",
            "['fünf', 'personen', ',', 'angeführt', 'von', 'einer', 'frau', 'in', 'einem', 'pinken', 'hemd', 'und', 'braunen', 'rock', ',', 'gehen', 'eine', 'treppe', 'hoch', '.']\n",
            "Encoder output torch.Size([1, 22, 256])\n",
            "251\n",
            "19\n",
            "15\n",
            "46\n",
            "22\n",
            "4\n",
            "90\n",
            "23\n",
            "15\n",
            "11\n",
            "4\n",
            "61\n",
            "23\n",
            "15\n",
            "41\n",
            "51\n",
            "4\n",
            "966\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'menschen', 'auf', 'einem', 'obstmarkt', 'im', 'freien', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "8\n",
            "4\n",
            "755\n",
            "1694\n",
            "341\n",
            "5\n",
            "3\n",
            "['zwei', 'jungen', 'essen', 'ihr', \"mcdonald's-menü\", 'im', 'außenbereich', ',', 'umgeben', 'von', 'vielen', 'anderen', 'leuten', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "16\n",
            "127\n",
            "17\n",
            "190\n",
            "66\n",
            "0\n",
            "6\n",
            "7\n",
            "177\n",
            "334\n",
            "49\n",
            "72\n",
            "19\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einer', 'jeansjacke', 'geht', 'auf', 'einem', 'gehweg', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "1049\n",
            "81\n",
            "10\n",
            "41\n",
            "8\n",
            "4\n",
            "84\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'fährt', 'ein', 'allradfahrzeug', 'mit', 'vier', 'passagieren', 'vorne', 'und', 'einem', 'seitlich', 'sitzenden', 'mann', 'hinten', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "9\n",
            "506\n",
            "4\n",
            "110\n",
            "42\n",
            "110\n",
            "42\n",
            "110\n",
            "42\n",
            "110\n",
            "42\n",
            "110\n",
            "42\n",
            "710\n",
            "15\n",
            "11\n",
            "16\n",
            "72\n",
            "9\n",
            "10\n",
            "671\n",
            "40\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'smaragdgrünen', 'hemd', 'liest', 'eine', 'zeitung', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "282\n",
            "23\n",
            "10\n",
            "218\n",
            "4\n",
            "556\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'in', 'einem', 'rutschfahrzeug', 'trägt', 'ein', 'grünes', 'shirt', 'und', 'hält', 'ein', 'buch', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "34\n",
            "6\n",
            "4\n",
            "0\n",
            "23\n",
            "10\n",
            "45\n",
            "4\n",
            "52\n",
            "23\n",
            "11\n",
            "45\n",
            "4\n",
            "277\n",
            "5\n",
            "3\n",
            "['zwei', 'kinder', 'sitzen', 'nebeneinander', 'und', 'essen', 'süßigkeiten', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "16\n",
            "63\n",
            "17\n",
            "32\n",
            "71\n",
            "18\n",
            "167\n",
            "72\n",
            "11\n",
            "190\n",
            "5\n",
            "3\n",
            "['radfahrer', 'auf', 'der', 'straße', ',', 'alle', 'tragen', 'helme', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "1078\n",
            "8\n",
            "7\n",
            "39\n",
            "255\n",
            "151\n",
            "469\n",
            "5\n",
            "3\n",
            "['menschengruppen', ',', 'die', 'alle', 'fahrrad', 'fahren', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "1185\n",
            "99\n",
            "467\n",
            "255\n",
            "78\n",
            "4\n",
            "99\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'sitzt', 'auf', 'einer', 'plattform', 'mit', 'rädern', 'und', 'wird', 'von', 'einem', 'esel', 'gezogen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "9\n",
            "91\n",
            "8\n",
            "4\n",
            "631\n",
            "13\n",
            "4\n",
            "825\n",
            "894\n",
            "49\n",
            "4\n",
            "1627\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'fährt', 'auf', 'einem', 'fahrrad', 'durch', 'einen', 'torbogen', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "78\n",
            "4\n",
            "99\n",
            "60\n",
            "4\n",
            "507\n",
            "5\n",
            "3\n",
            "['ein', 'bunt', 'gekleideter', 'junger', 'mann', 'mit', 'sichtbaren', 'hautverletzungen', 'sitzt', 'und', 'raucht', 'eine', 'zigarette', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "22\n",
            "4\n",
            "24\n",
            "9\n",
            "13\n",
            "549\n",
            "0\n",
            "10\n",
            "539\n",
            "4\n",
            "516\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'in', 'anzügen', 'unter', 'einem', 'regenschirm', 'vor', 'einem', 'graffiti', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "16\n",
            "30\n",
            "6\n",
            "623\n",
            "863\n",
            "4\n",
            "291\n",
            "108\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "390\n",
            "5\n",
            "3\n",
            "['ein', 'dünner', 'alter', 'mann', 'trägt', 'ein', 'schmutziges', 'weißes', 'hemd', 'und', 'fährt', 'fahrrad', 'auf', 'der', 'straße', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "21\n",
            "145\n",
            "9\n",
            "22\n",
            "4\n",
            "26\n",
            "765\n",
            "23\n",
            "11\n",
            "86\n",
            "1612\n",
            "8\n",
            "7\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'versucht', ',', 'einen', 'jungen', 'stier', 'von', 'einem', 'pferd', 'aus', 'mit', 'dem', 'seil', 'zu', 'fangen', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "9\n",
            "260\n",
            "18\n",
            "1438\n",
            "51\n",
            "21\n",
            "1112\n",
            "591\n",
            "65\n",
            "4\n",
            "560\n",
            "1017\n",
            "5\n",
            "3\n",
            "['ein', 'cowboy', 'versucht', 'von', 'einem', 'pferd', 'aus', 'ein', 'kalb', 'mit', 'dem', 'lasso', 'zu', 'fangen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "429\n",
            "10\n",
            "682\n",
            "18\n",
            "270\n",
            "65\n",
            "4\n",
            "198\n",
            "18\n",
            "366\n",
            "4\n",
            "1408\n",
            "5\n",
            "3\n",
            "['zwei', 'radfahrer', 'mit', 'helmen', 'fahren', 'an', 'ein', 'paar', 'abgeernteten', 'feldern', 'vorbei', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "16\n",
            "905\n",
            "78\n",
            "1092\n",
            "40\n",
            "4\n",
            "2367\n",
            "12\n",
            "74\n",
            "664\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'beugt', 'sich', 'zur', 'seite', 'und', 'zieht', 'etwas', 'aus', 'einer', 'tasche', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "475\n",
            "27\n",
            "265\n",
            "8\n",
            "4\n",
            "265\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'fährt', 'in', 'einem', 'motorisierten', 'wagen', 'vorbei', ',', 'um', 'den', 'park', 'zu', 'sehen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "9\n",
            "241\n",
            "27\n",
            "99\n",
            "1096\n",
            "18\n",
            "1007\n",
            "7\n",
            "118\n",
            "5\n",
            "3\n",
            "['eine', 'tätowierte', 'person', 'betrachtet', 'ein', 'foto', 'auf', 'einer', 'digitalkamera', 'oder', 'einem', 'handy', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "1350\n",
            "64\n",
            "10\n",
            "56\n",
            "20\n",
            "4\n",
            "116\n",
            "15\n",
            "258\n",
            "4\n",
            "2129\n",
            "116\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'schwarzen', 'hemd', 'und', 'jeans', 'steht', 'auf', 'dem', 'gehsteig', 'und', 'blickt', 'in', 'die', 'kamera', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "26\n",
            "23\n",
            "11\n",
            "175\n",
            "89\n",
            "8\n",
            "7\n",
            "84\n",
            "56\n",
            "20\n",
            "7\n",
            "116\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'und', 'ein', 'mädchen', 'stehen', 'gemeinsam', 'auf', 'dem', 'gehsteig', 'und', 'betrachten', 'einen', 'gegenstand', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "34\n",
            "11\n",
            "33\n",
            "17\n",
            "36\n",
            "129\n",
            "8\n",
            "7\n",
            "84\n",
            "56\n",
            "20\n",
            "21\n",
            "374\n",
            "5\n",
            "3\n",
            "['mehrere', 'personen', 'in', 'blauen', 'kitteln', 'und', 'eine', 'in', 'einem', 'rock', 'und', 'schwarzer', 'bluse', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "19\n",
            "17\n",
            "41\n",
            "6\n",
            "4\n",
            "238\n",
            "481\n",
            "11\n",
            "4\n",
            "29\n",
            "23\n",
            "11\n",
            "4\n",
            "26\n",
            "924\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'und', 'eine', 'hund', 'sitzen', 'auf', 'einer', 'weißen', 'bank', 'in', 'der', 'nähe', 'eines', 'strandes', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "14\n",
            "11\n",
            "4\n",
            "35\n",
            "17\n",
            "32\n",
            "8\n",
            "4\n",
            "144\n",
            "80\n",
            "4\n",
            "88\n",
            "5\n",
            "3\n",
            "['zwei', 'frauen', 'gehen', 'auf', 'der', 'erde', 'vor', 'einem', 'gebäude', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "50\n",
            "41\n",
            "8\n",
            "4\n",
            "170\n",
            "142\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "77\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'männern', 'und', 'ein', 'kind', 'in', 'weißen', 'shorts', 'stehen', 'auf', 'der', 'straße', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "30\n",
            "11\n",
            "4\n",
            "55\n",
            "6\n",
            "25\n",
            "148\n",
            "100\n",
            "8\n",
            "7\n",
            "39\n",
            "5\n",
            "3\n",
            "['eine', 'ganz', 'in', 'schwarz', 'gekleidete', 'frau', 'trägt', 'auf', 'dem', 'gehsteig', 'eine', 'schwarze', 'tasche', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "255\n",
            "26\n",
            "151\n",
            "4\n",
            "26\n",
            "265\n",
            "8\n",
            "7\n",
            "84\n",
            "5\n",
            "3\n",
            "['gruppe', 'von', 'männern', 'sitzt', 'an', 'einem', 'tisch', 'und', 'unterhält', 'sich', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "38\n",
            "12\n",
            "30\n",
            "32\n",
            "20\n",
            "4\n",
            "94\n",
            "11\n",
            "119\n",
            "5\n",
            "3\n",
            "['ein', 'wandgemälde', 'auf', 'einem', 'gebäude', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "4\n",
            "891\n",
            "10\n",
            "8\n",
            "4\n",
            "77\n",
            "5\n",
            "3\n",
            "['ein', 'asiatischer', 'mann', 'mit', 'handschuhen', 'arbeitet', 'an', 'einem', 'imbissstand', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "21\n",
            "106\n",
            "9\n",
            "22\n",
            "570\n",
            "465\n",
            "8\n",
            "4\n",
            "4817\n",
            "5\n",
            "3\n",
            "['frau', 'sitzt', 'an', 'einem', 'tisch', 'und', 'arbeitet', 'an', 'ihrem', 'laptop', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "14\n",
            "32\n",
            "20\n",
            "4\n",
            "94\n",
            "130\n",
            "8\n",
            "44\n",
            "776\n",
            "5\n",
            "3\n",
            "['eine', 'person', 'sieht', 'zum', 'computer', 'auf', 'einem', 'tisch', 'mit', 'einem', 'telefon', 'und', 'einer', 'schachtel', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "64\n",
            "56\n",
            "20\n",
            "418\n",
            "662\n",
            "8\n",
            "4\n",
            "349\n",
            "13\n",
            "4\n",
            "517\n",
            "518\n",
            "11\n",
            "4\n",
            "517\n",
            "518\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'sitzt', 'in', 'einem', 'stuhl', 'und', 'beobachtet', 'leute', ',', 'die', 'vorbeigehen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "32\n",
            "6\n",
            "4\n",
            "243\n",
            "173\n",
            "19\n",
            "152\n",
            "49\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'mit', 'hüten', 'stehen', 'auf', 'einem', 'feld', 'und', 'pflegen', 'nutzpflanzen', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "16\n",
            "19\n",
            "22\n",
            "279\n",
            "17\n",
            "36\n",
            "8\n",
            "4\n",
            "85\n",
            "13\n",
            "0\n",
            "5\n",
            "3\n",
            "['jemand', 'springt', 'in', 'barcelona', 'über', 'ein', 'reck', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "290\n",
            "92\n",
            "76\n",
            "4\n",
            "1790\n",
            "647\n",
            "347\n",
            "6\n",
            "7\n",
            "95\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'stiefeln', 'und', 'einem', 'cowboyhut', 'sitzt', 'auf', 'einem', 'springenden', 'pferd', 'während', 'zuschauer', 'auf', 'den', 'tribünen', 'sitzen', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "515\n",
            "11\n",
            "4\n",
            "429\n",
            "67\n",
            "91\n",
            "8\n",
            "4\n",
            "198\n",
            "28\n",
            "450\n",
            "8\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['zwei', 'junge', 'mädchen', 'sitzen', 'auf', 'der', 'straße', 'und', 'essen', 'mais', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "16\n",
            "24\n",
            "104\n",
            "17\n",
            "32\n",
            "8\n",
            "7\n",
            "39\n",
            "190\n",
            "5\n",
            "3\n",
            "['drei', 'kinder', 'in', 'footballtrikots', 'zweier', 'verschiedener', 'mannschaften', 'spielen', 'football', 'auf', 'einem', 'footballplatz', 'während', 'ein', 'weiterer', 'spieler', 'und', 'ein', 'erwachsener', 'im', 'hintergrund', 'stehen', '.']\n",
            "Encoder output torch.Size([1, 25, 256])\n",
            "48\n",
            "63\n",
            "6\n",
            "0\n",
            "0\n",
            "17\n",
            "37\n",
            "192\n",
            "226\n",
            "4\n",
            "192\n",
            "135\n",
            "28\n",
            "82\n",
            "105\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'kind', 'mit', 'schmutzigem', 'gesicht', 'wird', 'von', 'einer', 'alten', 'frau', 'gehalten', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "24\n",
            "55\n",
            "13\n",
            "765\n",
            "158\n",
            "10\n",
            "191\n",
            "852\n",
            "49\n",
            "21\n",
            "145\n",
            "14\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'brille', 'blickt', 'in', 'die', 'kamera', 'während', 'ein', 'anderer', 'mann', 'in', 'einem', 'blauen', 'hemd', 'sich', 'auf', 'etwas', 'konzentriert', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "4\n",
            "9\n",
            "13\n",
            "146\n",
            "56\n",
            "20\n",
            "7\n",
            "116\n",
            "28\n",
            "82\n",
            "9\n",
            "6\n",
            "4\n",
            "29\n",
            "23\n",
            "107\n",
            "8\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'sitzen', 'unter', 'einem', 'baum', 'mit', 'grünem', 'gemüse', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "19\n",
            "32\n",
            "199\n",
            "4\n",
            "159\n",
            "13\n",
            "52\n",
            "611\n",
            "5\n",
            "3\n",
            "['ein', 'kleiner', 'junge', 'mit', 'einer', 'blauen', 'mütze', 'blickt', 'durch', 'ein', 'teleskop', 'während', 'ein', 'anderer', 'junge', 'zusieht', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "53\n",
            "34\n",
            "6\n",
            "4\n",
            "29\n",
            "283\n",
            "107\n",
            "60\n",
            "4\n",
            "859\n",
            "28\n",
            "82\n",
            "34\n",
            "229\n",
            "5\n",
            "3\n",
            "['3', 'männer', 'kochen', 'in', 'einer', 'kleinen', 'küche', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "681\n",
            "30\n",
            "461\n",
            "4\n",
            "70\n",
            "284\n",
            "5\n",
            "3\n",
            "['ein', 'junges', 'mädchen', 'in', 'einem', 'grauen', 'schneeanzug', 'fährt', 'ski', 'auf', 'einem', 'verschneiten', 'berg', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "24\n",
            "33\n",
            "22\n",
            "4\n",
            "132\n",
            "1825\n",
            "15\n",
            "10\n",
            "772\n",
            "40\n",
            "4\n",
            "331\n",
            "221\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'dorfbewohnerinnen', 'versammelt', 'sich', 'beim', 'tanz', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "183\n",
            "1611\n",
            "17\n",
            "239\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'und', 'eine', 'frau', 'sortieren', 'wäsche', 'mit', 'latexhandschuhen', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "11\n",
            "4\n",
            "14\n",
            "17\n",
            "760\n",
            "74\n",
            "997\n",
            "1641\n",
            "5\n",
            "3\n",
            "['ein', 'junges', 'mädchen', 'sitzt', 'auf', 'einem', 'holzstuhl', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "4\n",
            "24\n",
            "33\n",
            "10\n",
            "32\n",
            "8\n",
            "4\n",
            "248\n",
            "243\n",
            "5\n",
            "3\n",
            "['zwei', 'arbeiter', 'verschweißen', 'die', 'stangen', 'eines', 'zauns', 'an', 'einer', 'viel', 'befahrenen', 'vorstadtstraße', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "16\n",
            "228\n",
            "0\n",
            "7\n",
            "109\n",
            "12\n",
            "4\n",
            "333\n",
            "108\n",
            "20\n",
            "4\n",
            "238\n",
            "481\n",
            "5\n",
            "3\n",
            "['ein', 'junger', 'mann', 'mit', 'langen', 'haaren', 'fährt', 'an', 'einem', 'bewölkten', 'tag', 'skateboard', 'auf', 'dem', 'geländer', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "13\n",
            "163\n",
            "97\n",
            "78\n",
            "4\n",
            "264\n",
            "8\n",
            "4\n",
            "264\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'schaufeln', 'auf', 'einem', 'freiluftmarkt', 'den', 'weg', 'von', 'schnee', 'und', 'matsch', 'frei', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "16\n",
            "30\n",
            "17\n",
            "78\n",
            "8\n",
            "4\n",
            "248\n",
            "302\n",
            "13\n",
            "4\n",
            "0\n",
            "11\n",
            "95\n",
            "5\n",
            "3\n",
            "['ein', 'typ', 'in', 'einem', 'weißen', 'hemd', 'spielt', 'auf', 'einer', 'weißen', 'gitarre', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "174\n",
            "6\n",
            "4\n",
            "25\n",
            "23\n",
            "10\n",
            "37\n",
            "4\n",
            "25\n",
            "126\n",
            "5\n",
            "3\n",
            "['ein', 'junges', 'mädchen', 'zeigt', 'seiner', 'freundin', ',', 'wie', 'man', 'eine', 'einwegkamera', 'verwendet', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "24\n",
            "33\n",
            "489\n",
            "44\n",
            "284\n",
            "340\n",
            "4\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'kleiner', 'junge', 'springt', 'von', 'einem', 'steg', 'in', 'einen', 'see', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "53\n",
            "34\n",
            "10\n",
            "92\n",
            "111\n",
            "4\n",
            "444\n",
            "69\n",
            "4\n",
            "318\n",
            "5\n",
            "3\n",
            "['eine', 'sehr', 'unglücklich', 'aussehende', 'dame', 'mit', 'einer', 'grünen', 'maske', 'beim', 'zahnarzt', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "262\n",
            "0\n",
            "120\n",
            "13\n",
            "4\n",
            "120\n",
            "6\n",
            "4\n",
            "52\n",
            "630\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'einer', 'orangen', 'jacke', 'und', 'blauem', 'mütze', 'klettert', 'auf', 'einen', 'verschneiten', 'berg', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "9\n",
            "13\n",
            "21\n",
            "86\n",
            "81\n",
            "11\n",
            "29\n",
            "283\n",
            "643\n",
            "8\n",
            "4\n",
            "331\n",
            "221\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'mädchen', 'mit', 'blonden', 'haaren', 'spielt', 'und', 'spritzt', 'in', 'einer', 'schlammpfütze', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "53\n",
            "122\n",
            "33\n",
            "13\n",
            "122\n",
            "42\n",
            "97\n",
            "10\n",
            "37\n",
            "6\n",
            "4\n",
            "1004\n",
            "5\n",
            "3\n",
            "['ein', 'kind', 'fährt', 'auf', 'einem', 'fahrrad', 'durch', 'eine', 'gasse', 'mit', 'einem', 'graffiti', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "55\n",
            "241\n",
            "4\n",
            "99\n",
            "60\n",
            "21\n",
            "641\n",
            "13\n",
            "4\n",
            "390\n",
            "5\n",
            "3\n",
            "['eine', 'turnerin', 'wird', 'bei', 'einer', 'veranstaltung', 'beurteilt', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "4\n",
            "183\n",
            "910\n",
            "10\n",
            "191\n",
            "0\n",
            "20\n",
            "21\n",
            "358\n",
            "5\n",
            "3\n",
            "['menschen', 'gehen', 'auf', 'einer', 'straße', 'mit', 'einem', 'straßenhändler', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "19\n",
            "41\n",
            "8\n",
            "4\n",
            "39\n",
            "13\n",
            "4\n",
            "39\n",
            "523\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'traditionellem', 'gewand', 'steht', 'neben', 'seinem', 'esel', ',', 'der', 'anscheinend', 'auch', 'bekleidet', 'ist', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "204\n",
            "981\n",
            "10\n",
            "36\n",
            "71\n",
            "18\n",
            "27\n",
            "1102\n",
            "5\n",
            "3\n",
            "['zwei', 'kinder', 'spielen', 'auf', 'einem', 'fahrrad', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "63\n",
            "17\n",
            "37\n",
            "8\n",
            "4\n",
            "99\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'aus', 'gegnerischen', 'mannschaften', 'spielen', 'fußball', 'auf', 'einem', 'fußballplatz', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "16\n",
            "30\n",
            "65\n",
            "1030\n",
            "639\n",
            "37\n",
            "123\n",
            "8\n",
            "4\n",
            "123\n",
            "85\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'springt', 'in', 'die', 'luft', 'und', 'posiert', 'für', 'fotografen', ',', 'die', 'auf', 'dem', 'boden', 'liegen', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "92\n",
            "6\n",
            "7\n",
            "103\n",
            "249\n",
            "54\n",
            "7\n",
            "771\n",
            "8\n",
            "7\n",
            "185\n",
            "5\n",
            "3\n",
            "['das', 'mädchen', 'trinkt', 'aus', 'einem', 'springbrunnen', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "7\n",
            "33\n",
            "10\n",
            "351\n",
            "75\n",
            "12\n",
            "4\n",
            "383\n",
            "5\n",
            "3\n",
            "['der', 'hobbyhöhlenforscher', 'findet', 'auf', 'seiner', 'wanderung', 'wasser', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "7\n",
            "0\n",
            "10\n",
            "8\n",
            "27\n",
            "1029\n",
            "17\n",
            "8\n",
            "7\n",
            "47\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'laborkittel', 'blickt', 'durch', 'ein', 'mikroskop', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "888\n",
            "193\n",
            "10\n",
            "56\n",
            "60\n",
            "4\n",
            "803\n",
            "5\n",
            "3\n",
            "['ein', 'blondes', 'mädchen', 'schläft', 'auf', 'einer', 'braunen', 'couch', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "122\n",
            "33\n",
            "375\n",
            "8\n",
            "4\n",
            "61\n",
            "425\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'kehrt', 'tagsüber', 'den', 'gehsteig', 'vor', 'einem', 'ziegelbau', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "1831\n",
            "7\n",
            "84\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "291\n",
            "77\n",
            "5\n",
            "3\n",
            "['drei', 'männer', 'kochen', 'in', 'einer', 'küche', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "48\n",
            "30\n",
            "461\n",
            "6\n",
            "4\n",
            "284\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'auf', 'einem', 'gerüst', 'vor', 'einem', 'haus', 'lächelt', 'und', 'posiert', 'für', 'den', 'fotografen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "9\n",
            "8\n",
            "1136\n",
            "10\n",
            "133\n",
            "54\n",
            "7\n",
            "356\n",
            "11\n",
            "249\n",
            "54\n",
            "7\n",
            "771\n",
            "5\n",
            "3\n",
            "['zwei', 'mädchen', 'in', 'shorts', 'halten', 'händchen', 'an', 'einem', 'pool', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "104\n",
            "6\n",
            "148\n",
            "608\n",
            "181\n",
            "6\n",
            "4\n",
            "162\n",
            "5\n",
            "3\n",
            "['vier', 'asiatische', 'kinder', 'sitzen', 'auf', 'einer', 'bank', 'und', 'winken', 'lächelnd', 'in', 'die', 'kamera', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "110\n",
            "106\n",
            "63\n",
            "32\n",
            "8\n",
            "4\n",
            "144\n",
            "133\n",
            "54\n",
            "7\n",
            "116\n",
            "5\n",
            "3\n",
            "['kinder', 'auf', 'fahrrädern', 'in', 'einem', 'scheinbar', 'verarmten', 'land', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "63\n",
            "78\n",
            "449\n",
            "6\n",
            "21\n",
            "0\n",
            "1906\n",
            "5\n",
            "3\n",
            "['ein', 'kleiner', 'junge', 'mit', 'kochmütze', 'und', 'schürze', 'schneidet', 'in', 'einer', 'küche', 'würstchen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "53\n",
            "34\n",
            "22\n",
            "4\n",
            "52\n",
            "502\n",
            "466\n",
            "69\n",
            "4\n",
            "284\n",
            "5\n",
            "3\n",
            "['das', 'ist', 'ein', 'clown', 'in', 'einer', 'grundschule', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "209\n",
            "10\n",
            "4\n",
            "735\n",
            "6\n",
            "4\n",
            "735\n",
            "372\n",
            "5\n",
            "3\n",
            "['der', 'schiffskapitän', 'lächelt', 'und', 'hält', 'das', 'steuerrad', 'seines', 'hölzernen', 'schiffs', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "7\n",
            "0\n",
            "346\n",
            "10\n",
            "133\n",
            "28\n",
            "45\n",
            "7\n",
            "448\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'gelber', 'bulldozer', 'schafft', 'erdreich', 'aus', 'dem', 'weg', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "62\n",
            "2679\n",
            "0\n",
            "18\n",
            "1046\n",
            "7\n",
            "302\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'roten', 'hemd', 'reitet', 'auf', 'einem', 'weißen', 'pferd', ',', 'das', 'an', 'den', 'bäumen', 'entlang', 'galoppiert', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "31\n",
            "23\n",
            "241\n",
            "4\n",
            "25\n",
            "198\n",
            "124\n",
            "7\n",
            "96\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'sitzt', 'vor', 'bäumen', 'im', 'hintergrund', 'auf', 'einem', 'sehr', 'großen', 'stein', 'und', 'lächelt', 'in', 'die', 'kamera', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "14\n",
            "91\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "262\n",
            "59\n",
            "166\n",
            "133\n",
            "20\n",
            "7\n",
            "116\n",
            "5\n",
            "3\n",
            "['drei', 'männer', 'in', 'bunten', 'kostümen', ',', 'perücken', 'und', 'verrückten', 'sonnenbrillen', 'gehen', 'auf', 'die', 'straße', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "48\n",
            "30\n",
            "6\n",
            "263\n",
            "567\n",
            "15\n",
            "11\n",
            "0\n",
            "15\n",
            "17\n",
            "41\n",
            "8\n",
            "7\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'mädchen', 'spielt', 'in', 'einem', 'kleinen', 'pool', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "4\n",
            "33\n",
            "10\n",
            "37\n",
            "6\n",
            "4\n",
            "70\n",
            "162\n",
            "5\n",
            "3\n",
            "['zwei', 'kinder', ',', 'ein', 'junge', 'in', 'einem', 'gelben', 'shirt', 'und', 'ein', 'mädchen', 'in', 'blau-weiß', 'gestreiften', 'klamotten', ',', 'schaukeln', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "16\n",
            "63\n",
            "15\n",
            "46\n",
            "34\n",
            "6\n",
            "4\n",
            "62\n",
            "23\n",
            "11\n",
            "62\n",
            "23\n",
            "15\n",
            "11\n",
            "26\n",
            "194\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'wirft', 'ein', 'fischernetz', 'in', 'die', 'bucht', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "411\n",
            "4\n",
            "377\n",
            "538\n",
            "69\n",
            "7\n",
            "103\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'einem', 'grauen', 'shirt', ',', 'blauen', 'jeans', 'und', 'neongrüner', 'sicherheitsweste', 'steht', 'mit', 'einem', 'weißen', 'lieferwagen', 'und', 'einem', 'weißen', 'gebäude', 'im', 'hintergrund', 'auf', 'einer', 'bahnstrecke', '.']\n",
            "Encoder output torch.Size([1, 29, 256])\n",
            "4\n",
            "9\n",
            "13\n",
            "4\n",
            "132\n",
            "23\n",
            "15\n",
            "29\n",
            "175\n",
            "15\n",
            "11\n",
            "4\n",
            "25\n",
            "23\n",
            "89\n",
            "13\n",
            "4\n",
            "25\n",
            "809\n",
            "12\n",
            "4\n",
            "77\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['zwei', 'bauarbeiter', 'legen', 'blech', 'über', 'balken', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "216\n",
            "228\n",
            "17\n",
            "0\n",
            "8\n",
            "7\n",
            "1308\n",
            "320\n",
            "5\n",
            "3\n",
            "['eine', 'band', 'mit', 'dezent', 'in', 'blau', 'gekleideten', 'bandmitgliedern', 'steht', 'auf', 'der', 'bühne', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "200\n",
            "13\n",
            "4\n",
            "204\n",
            "29\n",
            "6\n",
            "29\n",
            "89\n",
            "8\n",
            "149\n",
            "5\n",
            "3\n",
            "['ein', 'rocker', 'mit', 'freiem', 'oberkörper', 'singt', 'in', 'ein', 'mikrofon', 'während', 'er', 'schlagzeug', 'spielt', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "388\n",
            "122\n",
            "9\n",
            "10\n",
            "269\n",
            "69\n",
            "4\n",
            "220\n",
            "28\n",
            "37\n",
            "7\n",
            "534\n",
            "5\n",
            "3\n",
            "['ich', 'sehe', 'einen', 'mann', ',', 'der', 'die', 'artikel', 'aus', 'seinem', 'einkaufswagen', 'nimmt', 'um', 'zu', 'bezahlen', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "956\n",
            "1007\n",
            "7\n",
            "428\n",
            "12\n",
            "4\n",
            "9\n",
            "189\n",
            "10\n",
            "165\n",
            "695\n",
            "18\n",
            "462\n",
            "7\n",
            "332\n",
            "271\n",
            "5\n",
            "3\n",
            "['der', 'mann', 'mit', 'dem', 'spazierstock', 'macht', 'einen', 'spaziergang', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "7\n",
            "9\n",
            "13\n",
            "7\n",
            "41\n",
            "10\n",
            "165\n",
            "4\n",
            "152\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'weißen', 'pullover', 'trainiert', 'auf', 'einem', 'crosstrainer', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "25\n",
            "317\n",
            "10\n",
            "130\n",
            "8\n",
            "4\n",
            "248\n",
            "243\n",
            "5\n",
            "3\n",
            "['ein', 'mädchen', 'mit', 'einer', 'maske', 'reitet', 'auf', 'den', 'schultern', 'eines', 'mannes', 'durch', 'eine', 'menschenmenge', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "33\n",
            "13\n",
            "4\n",
            "630\n",
            "241\n",
            "4\n",
            "9\n",
            "78\n",
            "4\n",
            "157\n",
            "60\n",
            "4\n",
            "87\n",
            "5\n",
            "3\n",
            "['zwei', 'mädchen', ',', 'eines', 'älter', 'und', 'in', 'schwarz', ',', 'das', 'andere', 'jünger', 'und', 'in', 'weiß', ',', 'machen', 'dieselbe', 'tanzbewegung', 'vor', 'einer', 'dekoration', 'aus', 'ballons', '.']\n",
            "Encoder output torch.Size([1, 27, 256])\n",
            "16\n",
            "104\n",
            "15\n",
            "46\n",
            "22\n",
            "26\n",
            "15\n",
            "11\n",
            "46\n",
            "6\n",
            "26\n",
            "15\n",
            "11\n",
            "7\n",
            "72\n",
            "22\n",
            "25\n",
            "15\n",
            "17\n",
            "6\n",
            "25\n",
            "15\n",
            "17\n",
            "169\n",
            "4\n",
            "77\n",
            "6\n",
            "0\n",
            "75\n",
            "12\n",
            "4\n",
            "52\n",
            "11\n",
            "52\n",
            "15\n",
            "13\n",
            "72\n",
            "5\n",
            "3\n",
            "['mehrere', 'frauen', 'führen', 'vor', 'einem', 'gebäude', 'einen', 'tanz', 'auf', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "113\n",
            "50\n",
            "17\n",
            "186\n",
            "4\n",
            "330\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "77\n",
            "5\n",
            "3\n",
            "['ein', 'glatzköpfiger', 'mann', 'geht', 'auf', 'einem', 'gehsteig', 'und', 'telefoniert', 'mit', 'seinem', 'handy', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "683\n",
            "9\n",
            "10\n",
            "41\n",
            "8\n",
            "4\n",
            "84\n",
            "119\n",
            "8\n",
            "27\n",
            "349\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'spielt', 'mit', 'fingerpuppen', 'während', 'ein', 'kleines', 'kind', 'in', 'einem', 'kostüm', 'vorbeigeht', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "14\n",
            "137\n",
            "13\n",
            "4\n",
            "70\n",
            "55\n",
            "28\n",
            "4\n",
            "55\n",
            "6\n",
            "4\n",
            "372\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'leuten', 'beobachtet', 'junge', 'männer', ',', 'die', 'auf', 'eimern', 'schlagzeug', 'spielen', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "173\n",
            "24\n",
            "30\n",
            "128\n",
            "1275\n",
            "8\n",
            "7\n",
            "534\n",
            "5\n",
            "3\n",
            "['ein', 'mädchen', 'mit', 'gewöhnlicher', 'und', 'improvisierter', 'schutzausrüstung', 'fährt', 'rollerblades', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "33\n",
            "13\n",
            "0\n",
            "11\n",
            "4\n",
            "31\n",
            "11\n",
            "62\n",
            "1003\n",
            "352\n",
            "10\n",
            "78\n",
            "4\n",
            "661\n",
            "5\n",
            "3\n",
            "['ein', 'kleines', 'weißes', 'auto', 'steht', 'auf', 'den', 'bahngleisen', 'und', 'wurde', 'eventuell', 'vom', 'zug', 'im', 'hintergrund', 'gerammt', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "70\n",
            "25\n",
            "138\n",
            "10\n",
            "8\n",
            "7\n",
            "238\n",
            "1013\n",
            "373\n",
            "8\n",
            "7\n",
            "238\n",
            "1013\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['zwei', 'rocker', 'singen', 'und', 'spielen', 'auf', 'einer', 'dunklen', 'bühne', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "353\n",
            "215\n",
            "17\n",
            "37\n",
            "11\n",
            "8\n",
            "4\n",
            "149\n",
            "5\n",
            "3\n",
            "['ein', 'mädchen', 'mit', 'einer', 'baseballmütze', ',', 'weißem', 't-shirt', 'und', 'blauen', 'shorts', 'steht', 'in', 'einem', 'von', 'wald', 'umgebenen', 'gebirgsbach', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "4\n",
            "33\n",
            "6\n",
            "4\n",
            "188\n",
            "283\n",
            "15\n",
            "4\n",
            "25\n",
            "23\n",
            "11\n",
            "29\n",
            "148\n",
            "10\n",
            "36\n",
            "6\n",
            "4\n",
            "397\n",
            "334\n",
            "49\n",
            "250\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'spielen', 'gitarre', 'vor', 'einem', 'großen', 'publikum', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "16\n",
            "30\n",
            "37\n",
            "1275\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "59\n",
            "87\n",
            "5\n",
            "3\n",
            "['mehrere', 'leute', 'tanzen', 'vor', 'diesem', 'riesigen', 'haus', 'mit', 'ihren', 'partnern', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "113\n",
            "19\n",
            "17\n",
            "239\n",
            "6\n",
            "43\n",
            "12\n",
            "66\n",
            "715\n",
            "356\n",
            "13\n",
            "66\n",
            "364\n",
            "1169\n",
            "5\n",
            "3\n",
            "['frau', 'mit', 'hund', 'verkauft', 'ihre', 'ware', 'im', 'freien', 'auf', 'den', 'treppen', 'des', 'alten', 'gebäudes', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "14\n",
            "13\n",
            "35\n",
            "395\n",
            "1253\n",
            "57\n",
            "8\n",
            "7\n",
            "391\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'diskutiert', 'mit', 'zwei', 'professionell', 'gekleideten', 'männern', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "14\n",
            "10\n",
            "0\n",
            "16\n",
            "1306\n",
            "12\n",
            "30\n",
            "22\n",
            "86\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'männern', 'in', 'roten', 'und', 'schwarzen', 'jacken', 'sitzt', 'auf', 'motorrädern', 'und', 'wartet', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "30\n",
            "22\n",
            "31\n",
            "11\n",
            "26\n",
            "555\n",
            "32\n",
            "8\n",
            "1092\n",
            "254\n",
            "5\n",
            "3\n",
            "['ein', 'typ', 'in', 'einem', 'weißen', 'trikot', 'mit', 'der', 'nummer', '3', 'auf', 'dem', 'rücken', 'spielt', 'fußball', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "174\n",
            "6\n",
            "4\n",
            "25\n",
            "495\n",
            "13\n",
            "7\n",
            "448\n",
            "681\n",
            "8\n",
            "7\n",
            "182\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'verkauft', 'snacks', 'bei', 'einer', 'sportveranstaltung', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "4\n",
            "9\n",
            "395\n",
            "4\n",
            "1300\n",
            "358\n",
            "20\n",
            "4\n",
            "1300\n",
            "358\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', 'vom', 'grünen', 'team', 'tackeln', 'in', 'einem', 'rugbymatch', 'die', 'anderen', 'spieler', 'des', 'schwarzen', 'teams', ',', 'um', 'an', 'den', 'ball', 'zu', 'kommen', '.']\n",
            "Encoder output torch.Size([1, 25, 256])\n",
            "16\n",
            "30\n",
            "65\n",
            "1030\n",
            "237\n",
            "17\n",
            "92\n",
            "69\n",
            "7\n",
            "72\n",
            "6\n",
            "4\n",
            "52\n",
            "0\n",
            "192\n",
            "135\n",
            "12\n",
            "7\n",
            "72\n",
            "237\n",
            "5\n",
            "3\n",
            "['kinder', 'kämpfen', 'um', 'den', 'ballbesitz', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "63\n",
            "17\n",
            "658\n",
            "76\n",
            "7\n",
            "3585\n",
            "12\n",
            "7\n",
            "68\n",
            "5\n",
            "3\n",
            "['eine', 'person', 'in', 'blau', 'wirft', 'auf', 'einer', 'bowlingbahn', 'als', 'einzige', 'ihre', 'kugel', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "64\n",
            "6\n",
            "29\n",
            "782\n",
            "4\n",
            "503\n",
            "68\n",
            "58\n",
            "205\n",
            "0\n",
            "66\n",
            "503\n",
            "68\n",
            "5\n",
            "3\n",
            "['mehrere', 'fußballer', 'auf', 'einem', 'feld', 'in', 'aktion', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "113\n",
            "123\n",
            "215\n",
            "17\n",
            "6\n",
            "4\n",
            "85\n",
            "186\n",
            "5\n",
            "3\n",
            "['junger', 'mann', 'sitzt', 'auf', 'einem', 'skateboard', ',', 'hält', 'sein', 'handy', 'und', 'posiert', 'auf', 'der', 'rolltreppe', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "24\n",
            "9\n",
            "32\n",
            "8\n",
            "4\n",
            "264\n",
            "15\n",
            "45\n",
            "27\n",
            "286\n",
            "11\n",
            "10\n",
            "249\n",
            "5\n",
            "3\n",
            "['eine', 'blau', 'gekleidete', 'frau', 'läuft', 'einen', 'marathon', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "29\n",
            "79\n",
            "4\n",
            "644\n",
            "5\n",
            "3\n",
            "['diese', 'band', 'bereitet', 'sich', 'auf', 'einen', 'auftritt', 'vor', 'publikum', 'in', 'einer', 'kirche', 'vor', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "860\n",
            "17\n",
            "257\n",
            "312\n",
            "18\n",
            "508\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "764\n",
            "5\n",
            "3\n",
            "['die', '#', '8', 'von', 'iowa', 'state', 'streckt', 'den', 'arm', 'in', 'richtung', 'eines', 'spielers', 'der', 'texas', 'am', 'beim', 'versuch', ',', 'ihn', 'zu', 'tackeln', '.']\n",
            "Encoder output torch.Size([1, 25, 256])\n",
            "7\n",
            "192\n",
            "237\n",
            "1435\n",
            "0\n",
            "7\n",
            "46\n",
            "12\n",
            "7\n",
            "46\n",
            "394\n",
            "136\n",
            "27\n",
            "394\n",
            "6\n",
            "7\n",
            "103\n",
            "58\n",
            "205\n",
            "1602\n",
            "18\n",
            "366\n",
            "7\n",
            "68\n",
            "5\n",
            "3\n",
            "['zwei', 'männliche', 'curler', 'sind', 'auf', 'dem', 'eis', 'und', 'wischen', 'den', 'pfad', 'vor', 'dem', 'stein', ',', 'während', 'eine', 'kleine', 'menschenmenge', 'zusieht', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "16\n",
            "161\n",
            "5817\n",
            "17\n",
            "92\n",
            "8\n",
            "7\n",
            "261\n",
            "42\n",
            "710\n",
            "261\n",
            "15\n",
            "28\n",
            "4\n",
            "485\n",
            "19\n",
            "6\n",
            "43\n",
            "12\n",
            "155\n",
            "5\n",
            "3\n",
            "['männer', 'spielen', 'auf', 'einem', 'matschigen', 'platz', 'fußball', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "30\n",
            "37\n",
            "123\n",
            "8\n",
            "4\n",
            "85\n",
            "6\n",
            "4\n",
            "806\n",
            "5\n",
            "3\n",
            "['ein', 'basketballspieler', 'in', 'weiß', 'geht', 'in', 'die', 'hocke', 'während', 'ein', 'spieler', 'in', 'rot', 'auf', 'ihn', 'zu', 'läuft', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "224\n",
            "105\n",
            "6\n",
            "25\n",
            "10\n",
            "41\n",
            "69\n",
            "4\n",
            "105\n",
            "28\n",
            "7\n",
            "105\n",
            "6\n",
            "31\n",
            "10\n",
            "79\n",
            "5\n",
            "3\n",
            "['menschen', 'gehen', 'durch', 'einen', 'torbogen', 'in', 'einer', 'alt', 'aussehenden', 'stadt', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "19\n",
            "41\n",
            "60\n",
            "4\n",
            "1294\n",
            "20\n",
            "4\n",
            "101\n",
            "5\n",
            "3\n",
            "['zwei', 'rennautos', ',', 'eines', 'rot', 'und', 'das', 'andere', 'blau', ',', 'fahren', 'nebeneinander', 'auf', 'einer', 'rennstrecke', 'während', 'mehrere', 'personen', 'zusehen', '.']\n",
            "Encoder output torch.Size([1, 22, 256])\n",
            "16\n",
            "164\n",
            "492\n",
            "15\n",
            "46\n",
            "22\n",
            "31\n",
            "11\n",
            "46\n",
            "29\n",
            "15\n",
            "17\n",
            "78\n",
            "156\n",
            "167\n",
            "72\n",
            "58\n",
            "4\n",
            "164\n",
            "138\n",
            "17\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['ein', 'footballspieler', 'in', 'einem', 'weißen', 'trikot', 'hält', 'einen', 'football', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "192\n",
            "105\n",
            "6\n",
            "4\n",
            "25\n",
            "495\n",
            "10\n",
            "45\n",
            "4\n",
            "192\n",
            "5\n",
            "3\n",
            "['ein', 'sehr', 'kleiner', 'junge', 'guckt', 'nach', 'vorne', 'während', 'er', 'in', 'einen', 'kleinen', 'gegenstand', 'beißt', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "262\n",
            "24\n",
            "34\n",
            "10\n",
            "56\n",
            "76\n",
            "27\n",
            "500\n",
            "374\n",
            "69\n",
            "4\n",
            "70\n",
            "374\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'und', 'ein', 'kind', 'gehen', 'eine', 'straße', 'entlang', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "14\n",
            "11\n",
            "4\n",
            "55\n",
            "41\n",
            "40\n",
            "4\n",
            "39\n",
            "5\n",
            "3\n",
            "['ein', 'hockeyspiel', 'wird', 'vor', 'großem', 'publikum', 'gespielt', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "353\n",
            "353\n",
            "215\n",
            "191\n",
            "2393\n",
            "54\n",
            "4\n",
            "164\n",
            "5\n",
            "3\n",
            "['drei', 'frauen', 'springen', 'im', 'gras', 'auf', 'bällen', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "48\n",
            "50\n",
            "270\n",
            "8\n",
            "7\n",
            "810\n",
            "6\n",
            "7\n",
            "757\n",
            "5\n",
            "3\n",
            "['ein', 'afroamerikanischer', 'junge', 'in', 'blauen', 'shorts', ',', 'einem', 'schwarz-roten', 'shirt', 'und', 'weißen', 'turnschuhen', 'spielt', 'tennis', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "21\n",
            "324\n",
            "327\n",
            "34\n",
            "22\n",
            "4\n",
            "29\n",
            "148\n",
            "15\n",
            "23\n",
            "15\n",
            "11\n",
            "4\n",
            "25\n",
            "23\n",
            "15\n",
            "37\n",
            "213\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'und', 'eine', 'frau', 'in', 'weißen', 'shirts', 'umarmen', 'sich', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "11\n",
            "4\n",
            "14\n",
            "6\n",
            "25\n",
            "242\n",
            "17\n",
            "2008\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'einer', 'art', 'messsonde', 'spricht', 'mit', 'einer', 'familie', ',', 'die', 'versucht', ',', 'zu', 'lächeln', 'und', 'freundlich', 'zu', 'sein', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "4\n",
            "9\n",
            "13\n",
            "74\n",
            "688\n",
            "12\n",
            "0\n",
            "10\n",
            "119\n",
            "18\n",
            "4\n",
            "355\n",
            "189\n",
            "17\n",
            "260\n",
            "18\n",
            "366\n",
            "4\n",
            "355\n",
            "5\n",
            "3\n",
            "['sehr', 'kleiner', 'junge', 'in', 'einem', 'grünen', 'shirt', 'liegt', 'mit', 'dem', 'gesicht', 'nach', 'unten', 'auf', 'einem', 'weißen', 'bett', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "262\n",
            "24\n",
            "34\n",
            "6\n",
            "4\n",
            "52\n",
            "23\n",
            "273\n",
            "40\n",
            "13\n",
            "4\n",
            "25\n",
            "158\n",
            "8\n",
            "4\n",
            "478\n",
            "5\n",
            "3\n",
            "['ein', 'extremradfahrer', 'ruht', 'sich', 'aus', 'während', 'im', 'hintergrund', 'die', 'sonne', 'untergeht', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "0\n",
            "2826\n",
            "790\n",
            "111\n",
            "7\n",
            "284\n",
            "226\n",
            "7\n",
            "427\n",
            "5\n",
            "3\n",
            "['eine', 'warm', 'gekleidete', 'frau', 'fährt', 'in', 'einem', 'verschneiten', 'gebiet', 'ski', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "14\n",
            "73\n",
            "6\n",
            "26\n",
            "10\n",
            "772\n",
            "40\n",
            "4\n",
            "331\n",
            "177\n",
            "5\n",
            "3\n",
            "['vier', 'mädchen', 'und', 'eine', 'frau', 'lernen', 'zu', 'basteln', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "110\n",
            "104\n",
            "11\n",
            "4\n",
            "14\n",
            "17\n",
            "169\n",
            "1626\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'schwarz-weiß', 'gestreifter', 'kleidung', 'versucht', ',', 'ein', 'pferd', 'anzuhalten', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "26\n",
            "11\n",
            "25\n",
            "0\n",
            "10\n",
            "260\n",
            "18\n",
            "5315\n",
            "4\n",
            "198\n",
            "5\n",
            "3\n",
            "['der', 'herr', 'scannt', 'das', 'bild', ',', 'das', 'ihm', 'die', 'frau', 'im', 'blauen', 'hemd', 'zeigt', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "7\n",
            "524\n",
            "0\n",
            "7\n",
            "134\n",
            "12\n",
            "7\n",
            "14\n",
            "6\n",
            "7\n",
            "29\n",
            "23\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'mit', 'roten', 'haaren', 'steht', 'bis', 'zum', 'hals', 'in', 'trübem', 'blauem', 'wasser', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "14\n",
            "13\n",
            "31\n",
            "42\n",
            "97\n",
            "89\n",
            "8\n",
            "44\n",
            "936\n",
            "6\n",
            "29\n",
            "11\n",
            "29\n",
            "0\n",
            "5\n",
            "3\n",
            "['zwei', 'kleine', 'jungen', 'posieren', 'mit', 'einem', 'welpen', 'für', 'eine', 'familienfoto', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "16\n",
            "24\n",
            "127\n",
            "249\n",
            "13\n",
            "4\n",
            "1811\n",
            "403\n",
            "54\n",
            "4\n",
            "223\n",
            "5\n",
            "3\n",
            "['vier', 'kinder', 'üben', 'karate', 'während', 'zwei', 'erwachsene', 'zusehen', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "110\n",
            "63\n",
            "572\n",
            "836\n",
            "1128\n",
            "8\n",
            "16\n",
            "326\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'liegt', 'auf', 'einem', 'sofa', 'in', 'einem', 'möbelhaus', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "273\n",
            "8\n",
            "4\n",
            "425\n",
            "6\n",
            "4\n",
            "243\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'leuten', 'unterhält', 'sich', 'an', 'tischen', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "17\n",
            "119\n",
            "18\n",
            "167\n",
            "72\n",
            "5\n",
            "3\n",
            "['zwei', 'jockeys', ',', 'einer', 'in', 'rot-blauen', 'karos', 'und', 'der', 'andere', 'in', 'orange', 'und', 'braun', ',', 'liefern', 'sich', 'ein', 'rennen', 'vor', 'einem', 'verschwommenen', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 26, 256])\n",
            "16\n",
            "2322\n",
            "15\n",
            "46\n",
            "6\n",
            "4\n",
            "0\n",
            "11\n",
            "7\n",
            "72\n",
            "22\n",
            "86\n",
            "11\n",
            "86\n",
            "15\n",
            "17\n",
            "0\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "2303\n",
            "85\n",
            "5\n",
            "3\n",
            "['das', 'rote', 'auto', 'fährt', 'vor', 'den', 'beiden', 'autos', 'im', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "7\n",
            "31\n",
            "138\n",
            "10\n",
            "506\n",
            "7\n",
            "138\n",
            "6\n",
            "43\n",
            "12\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['ein', 'großer', 'stier', 'versucht', 'einen', 'mann', 'bei', 'einem', 'rodeo', 'auf', 'die', 'hörner', 'zu', 'nehmen', 'während', 'ein', 'rodeoclown', 'herbeiläuft', ',', 'um', 'zu', 'helfen', '.']\n",
            "Encoder output torch.Size([1, 25, 256])\n",
            "4\n",
            "59\n",
            "591\n",
            "10\n",
            "682\n",
            "18\n",
            "544\n",
            "4\n",
            "560\n",
            "20\n",
            "7\n",
            "560\n",
            "226\n",
            "4\n",
            "560\n",
            "575\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'ohne', 'hemd', 'geht', 'zu', 'einem', 'gelben', 'kajak', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "388\n",
            "9\n",
            "41\n",
            "8\n",
            "4\n",
            "62\n",
            "994\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'zielt', 'und', 'schießt', 'auf', 'einem', 'schießstand', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "34\n",
            "2646\n",
            "11\n",
            "3657\n",
            "8\n",
            "4\n",
            "5079\n",
            "5\n",
            "3\n",
            "['zwei', 'jugendteams', 'spielen', 'football', 'im', 'sand', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "0\n",
            "37\n",
            "192\n",
            "6\n",
            "7\n",
            "211\n",
            "5\n",
            "3\n",
            "['ein', 'kind', 'in', 'blau', 'und', 'ein', 'kind', 'in', 'weiß', 'stehen', 'auf', 'einer', 'niedrigen', 'betonmauer', 'neben', 'einem', 'fluss', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "55\n",
            "6\n",
            "29\n",
            "11\n",
            "4\n",
            "55\n",
            "36\n",
            "8\n",
            "4\n",
            "912\n",
            "71\n",
            "18\n",
            "4\n",
            "309\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'malt', 'ein', 'blumenmuster', 'auf', 'einen', 'tontopf', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "14\n",
            "10\n",
            "321\n",
            "4\n",
            "332\n",
            "271\n",
            "8\n",
            "4\n",
            "291\n",
            "259\n",
            "5\n",
            "3\n",
            "['leute', 'gehen', 'auf', 'einer', 'belebten', 'straße', 'in', 'einem', 'fremden', 'land', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "19\n",
            "17\n",
            "41\n",
            "8\n",
            "4\n",
            "345\n",
            "39\n",
            "6\n",
            "4\n",
            "345\n",
            "177\n",
            "5\n",
            "3\n",
            "['ein', 'rechtshändiger', 'pitcher', 'der', 'saints', 'wirft', 'einen', 'ball', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "188\n",
            "939\n",
            "782\n",
            "4\n",
            "0\n",
            "68\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', ',', 'einer', 'in', 'schwarz', 'und', 'weiß', 'und', 'einer', 'in', 'rot', ',', 'spielen', 'beachvolleyball', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "16\n",
            "30\n",
            "15\n",
            "46\n",
            "6\n",
            "26\n",
            "11\n",
            "46\n",
            "6\n",
            "25\n",
            "15\n",
            "17\n",
            "37\n",
            "6\n",
            "31\n",
            "15\n",
            "10\n",
            "37\n",
            "88\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'steht', 'in', 'einem', 'boot', 'und', 'flickt', 'netze', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "36\n",
            "6\n",
            "4\n",
            "180\n",
            "714\n",
            "7\n",
            "259\n",
            "5\n",
            "3\n",
            "['ein', 'surfer', ',', 'der', 'im', 'ozean', 'beim', 'versuch', ',', 'auf', 'einer', 'welle', 'zu', 'reiten', ',', 'von', 'seinem', 'brett', 'gefallen', 'ist', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "4\n",
            "552\n",
            "797\n",
            "4\n",
            "335\n",
            "8\n",
            "27\n",
            "347\n",
            "380\n",
            "4\n",
            "335\n",
            "5\n",
            "3\n",
            "['ein', 'techniker', 'bereitet', 'im', 'labor', 'eine', 'probe', 'vor', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "2465\n",
            "648\n",
            "10\n",
            "257\n",
            "586\n",
            "4\n",
            "586\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "2827\n",
            "5\n",
            "3\n",
            "['fußballer', 'springen', 'in', 'die', 'luft', ',', 'um', 'den', 'ball', 'mit', 'dem', 'kopf', 'zu', 'treffen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "123\n",
            "215\n",
            "270\n",
            "69\n",
            "7\n",
            "103\n",
            "18\n",
            "2359\n",
            "7\n",
            "68\n",
            "13\n",
            "27\n",
            "172\n",
            "5\n",
            "3\n",
            "['zwei', 'jungen', 'spielen', 'gegeneinander', 'fußball', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "16\n",
            "127\n",
            "37\n",
            "123\n",
            "5\n",
            "3\n",
            "['eine', 'ältere', 'person', 'überquert', 'die', 'straße', 'mit', 'einem', 'regenschirm', 'in', 'der', 'hand', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "21\n",
            "115\n",
            "64\n",
            "483\n",
            "7\n",
            "39\n",
            "13\n",
            "21\n",
            "297\n",
            "5\n",
            "3\n",
            "['eine', 'gruppe', 'von', 'läufern', 'läuft', 'auf', 'zwei', 'identische', 'wolkenkratzer', 'zu', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "38\n",
            "12\n",
            "19\n",
            "17\n",
            "41\n",
            "8\n",
            "4\n",
            "88\n",
            "302\n",
            "5\n",
            "3\n",
            "['ein', 'skateboarder', 'fährt', 'eine', 'betonwand', 'hoch', 'und', 'fällt', 'beinahe', 'beim', 'versuch', ',', 'einen', 'trick', 'zu', 'machen', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "480\n",
            "10\n",
            "78\n",
            "4\n",
            "434\n",
            "108\n",
            "11\n",
            "749\n",
            "111\n",
            "4\n",
            "1790\n",
            "647\n",
            "1028\n",
            "5\n",
            "3\n",
            "['leute', 'spielen', 'ein', 'spiel', 'im', 'pool', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "19\n",
            "37\n",
            "4\n",
            "135\n",
            "6\n",
            "7\n",
            "162\n",
            "5\n",
            "3\n",
            "['ein', 'typ', 'küsst', 'einen', 'anderen', 'typ']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "4\n",
            "174\n",
            "10\n",
            "659\n",
            "82\n",
            "174\n",
            "102\n",
            "182\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'schreibt', 'einem', 'kleinen', 'jungen', 'ein', 'autogramm', 'ins', 'buch', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "680\n",
            "4\n",
            "24\n",
            "34\n",
            "10\n",
            "680\n",
            "8\n",
            "4\n",
            "70\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'junger', 'mann', 'in', 'einem', 'blauen', 'shirt', 'fährt', 'in', 'einer', 'städtischen', 'gegend', 'über', 'ein', 'geländer', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "4\n",
            "24\n",
            "9\n",
            "6\n",
            "4\n",
            "29\n",
            "23\n",
            "241\n",
            "4\n",
            "709\n",
            "177\n",
            "76\n",
            "4\n",
            "2019\n",
            "5\n",
            "3\n",
            "['ein', 'asiate', 'sitzt', 'mit', 'kisten', 'von', 'erdnüssen', 'auf', 'der', 'straße', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "21\n",
            "106\n",
            "9\n",
            "91\n",
            "8\n",
            "7\n",
            "39\n",
            "13\n",
            "925\n",
            "361\n",
            "75\n",
            "5\n",
            "3\n",
            "['ein', 'britischer', 'gentleman', 'in', 'voller', 'militärischer', 'uniform', 'winkt', 'mit', 'seiner', 'mütze', 'leuten', 'zu', ',', 'die', 'im', 'hintergrund', 'sitzen', 'und', 'auf', 'den', 'kanal', 'blicken', '.']\n",
            "Encoder output torch.Size([1, 26, 256])\n",
            "4\n",
            "0\n",
            "0\n",
            "6\n",
            "4\n",
            "602\n",
            "231\n",
            "10\n",
            "691\n",
            "27\n",
            "283\n",
            "6\n",
            "7\n",
            "168\n",
            "12\n",
            "19\n",
            "32\n",
            "11\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "['zwei', 'autos', 'fahren', 'auf', 'einer', 'rennstrecke', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "16\n",
            "492\n",
            "78\n",
            "8\n",
            "4\n",
            "1290\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'schwarz-weißen', 'trikot', 'hält', 'gelbe', 'skistöcke', 'und', 'bereitet', 'sich', 'auf', 'den', 'start', 'vor', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "26\n",
            "11\n",
            "25\n",
            "314\n",
            "109\n",
            "10\n",
            "257\n",
            "312\n",
            "18\n",
            "677\n",
            "27\n",
            "158\n",
            "5\n",
            "3\n",
            "['zwei', 'personen', 'liegen', 'auf', 'einem', 'rasen', 'und', 'küssen', 'sich', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "19\n",
            "17\n",
            "273\n",
            "8\n",
            "4\n",
            "595\n",
            "11\n",
            "659\n",
            "5\n",
            "3\n",
            "['ein', 'sehr', 'kleines', 'kind', 'mit', 'einer', 'jeansmütze', 'isst', 'einen', 'grünen', 'apfel', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "262\n",
            "24\n",
            "55\n",
            "10\n",
            "190\n",
            "21\n",
            "1353\n",
            "190\n",
            "5\n",
            "3\n",
            "['die', 'footballspieler', 'laufen', ',', 'um', 'den', 'ball', 'zu', 'fangen', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "7\n",
            "192\n",
            "215\n",
            "17\n",
            "79\n",
            "18\n",
            "366\n",
            "7\n",
            "68\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'kariertem', 'hut', 'in', 'einer', 'schwarzen', 'jacke', 'und', 'einer', 'schwarz-weiß', 'gestreiften', 'hose', 'spielt', 'auf', 'einer', 'bühne', 'mit', 'einem', 'sänger', 'und', 'einem', 'weiteren', 'gitarristen', 'im', 'hintergrund', 'auf', 'einer', 'e-gitarre', '.']\n",
            "Encoder output torch.Size([1, 33, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "384\n",
            "67\n",
            "15\n",
            "26\n",
            "81\n",
            "11\n",
            "26\n",
            "194\n",
            "148\n",
            "15\n",
            "11\n",
            "4\n",
            "194\n",
            "16\n",
            "72\n",
            "8\n",
            "4\n",
            "149\n",
            "13\n",
            "4\n",
            "220\n",
            "8\n",
            "4\n",
            "149\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'springt', 'von', 'einem', 'stier', 'weg', 'über', 'eine', 'absperrung', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "9\n",
            "179\n",
            "111\n",
            "4\n",
            "591\n",
            "76\n",
            "4\n",
            "591\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'blauen', 'shirt', 'und', 'weißen', 'shorts', 'spielt', 'tennis', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "29\n",
            "23\n",
            "11\n",
            "25\n",
            "148\n",
            "137\n",
            "213\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'spielt', 'ein', 'intermezzo', 'in', 'einem', 'konzert', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "37\n",
            "4\n",
            "1469\n",
            "135\n",
            "6\n",
            "4\n",
            "505\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'trägt', 'eine', 'große', 'ladung', 'von', 'metallstäben', 'auf', 'seiner', 'schulter', 'durch', 'ein', 'holzlager', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "9\n",
            "504\n",
            "4\n",
            "59\n",
            "0\n",
            "12\n",
            "424\n",
            "8\n",
            "27\n",
            "675\n",
            "5\n",
            "3\n",
            "['frau', 'mit', 'kamera', 'wirft', 'ihrem', 'braunen', 'hund', 'einen', 'frisbee', 'zum', 'fangen', 'zu', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "14\n",
            "13\n",
            "116\n",
            "18\n",
            "366\n",
            "4\n",
            "61\n",
            "35\n",
            "18\n",
            "366\n",
            "4\n",
            "409\n",
            "5\n",
            "3\n",
            "['die', 'silhouette', 'eines', 'mannes', 'und', 'einer', 'frau', ',', 'die', 'ein', 'großes', 'bonfire', 'oder', 'einen', 'anderen', 'großen', ',', 'brennenden', 'holzgegenstand', 'betrachten', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "4\n",
            "2065\n",
            "12\n",
            "4\n",
            "9\n",
            "11\n",
            "4\n",
            "14\n",
            "15\n",
            "4\n",
            "59\n",
            "0\n",
            "258\n",
            "2892\n",
            "258\n",
            "0\n",
            "5\n",
            "3\n",
            "['zwei', 'mädchen', 'tauchen', 'ihre', 'hände', 'in', 'einen', 'springbrunnen', 'während', 'leute', 'vorbeigehen', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "16\n",
            "104\n",
            "0\n",
            "66\n",
            "181\n",
            "69\n",
            "4\n",
            "383\n",
            "28\n",
            "19\n",
            "152\n",
            "49\n",
            "5\n",
            "3\n",
            "['ein', 'nasses', ',', 'lächelndes', 'kind', 'ohne', 'hemd', 'posiert', 'mit', 'seinen', 'armen', 'in', 'der', 'luft', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "586\n",
            "55\n",
            "13\n",
            "4\n",
            "26\n",
            "23\n",
            "436\n",
            "13\n",
            "27\n",
            "364\n",
            "1874\n",
            "5\n",
            "3\n",
            "['zwei', 'männer', ',', 'einer', 'in', 'weiß', 'und', 'einer', 'in', 'blau', ',', 'ringen', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "16\n",
            "30\n",
            "15\n",
            "46\n",
            "6\n",
            "25\n",
            "11\n",
            "46\n",
            "6\n",
            "4\n",
            "29\n",
            "300\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einem', 'roten', 'bikini', 'springt', 'beim', 'volleyball', 'am', 'strand', 'hoch', ',', 'um', 'einen', 'ball', 'zu', 'treffen', '.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "31\n",
            "590\n",
            "10\n",
            "92\n",
            "51\n",
            "58\n",
            "7\n",
            "408\n",
            "8\n",
            "7\n",
            "88\n",
            "5\n",
            "3\n",
            "['kätzchen', 'mit', 'orangen', 'streifen', 'beißt', 'blondes', 'mädchen', 'in', 'die', 'nase', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "209\n",
            "0\n",
            "13\n",
            "44\n",
            "586\n",
            "122\n",
            "33\n",
            "1857\n",
            "44\n",
            "913\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'in', 'einer', 'gelben', 'schürze', 'nimmt', 'den', 'deckel', 'von', 'einem', 'großen', 'topf', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "62\n",
            "502\n",
            "10\n",
            "165\n",
            "4\n",
            "59\n",
            "1001\n",
            "12\n",
            "4\n",
            "59\n",
            "1001\n",
            "5\n",
            "3\n",
            "['zwei', 'kinder', 'überqueren', 'einen', 'kleinen', 'bach', 'über', 'eine', 'steinbrücke', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "16\n",
            "63\n",
            "472\n",
            "4\n",
            "70\n",
            "1011\n",
            "76\n",
            "4\n",
            "287\n",
            "177\n",
            "5\n",
            "3\n",
            "['zwei', 'afroamerikanische', 'frauen', 'fahren', 'auf', 'einem', 'moped', 'auf', 'einer', 'städtischen', 'straße', ',', 'die', 'sich', 'anscheinend', 'in', 'einem', 'großstadtgebiet', 'mit', 'stau', 'befindet', '.']\n",
            "Encoder output torch.Size([1, 24, 256])\n",
            "16\n",
            "324\n",
            "327\n",
            "0\n",
            "17\n",
            "78\n",
            "8\n",
            "4\n",
            "101\n",
            "39\n",
            "232\n",
            "4\n",
            "101\n",
            "39\n",
            "6\n",
            "4\n",
            "977\n",
            "207\n",
            "5\n",
            "3\n",
            "['zwei', 'jungen', 'vor', 'einem', 'getränkeautomaten', '.']\n",
            "Encoder output torch.Size([1, 8, 256])\n",
            "16\n",
            "127\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "0\n",
            "5\n",
            "3\n",
            "['radfahrer', 'in', 'schwarz', 'fährt', 'auf', 'einem', 'mountainbike', 'einen', 'unbefestigten', 'pfad', 'hinunter', '.']\n",
            "Encoder output torch.Size([1, 14, 256])\n",
            "1078\n",
            "6\n",
            "26\n",
            "15\n",
            "78\n",
            "4\n",
            "221\n",
            "99\n",
            "40\n",
            "4\n",
            "170\n",
            "438\n",
            "5\n",
            "3\n",
            "['eine', 'frau', 'mit', 'tattoos', 'macht', 'mit', 'ihrem', 'handy', 'ein', 'foto', 'von', 'einem', 'gemälde', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "4\n",
            "14\n",
            "13\n",
            "1456\n",
            "10\n",
            "165\n",
            "4\n",
            "134\n",
            "13\n",
            "44\n",
            "349\n",
            "8\n",
            "4\n",
            "321\n",
            "5\n",
            "3\n",
            "['eine', 'überwiegend', 'schwarz', 'gekleidete', 'frau', 'mit', 'einem', 'weißen', 'helm', 'fährt', 'vor', 'verschwommenen', 'bäumen', 'im', 'hintergrund', 'fahrrad', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "26\n",
            "300\n",
            "22\n",
            "4\n",
            "25\n",
            "234\n",
            "10\n",
            "78\n",
            "4\n",
            "99\n",
            "6\n",
            "43\n",
            "12\n",
            "250\n",
            "6\n",
            "43\n",
            "12\n",
            "250\n",
            "5\n",
            "3\n",
            "['ein', 'team', 'von', 'radfahrern', 'fährt', 'um', 'die', 'kurve', 'während', 'in', 'zuschauer', 'der', 'nähe', 'jubeln', 'und', 'fotos', 'machen', '.']\n",
            "Encoder output torch.Size([1, 20, 256])\n",
            "4\n",
            "237\n",
            "12\n",
            "905\n",
            "281\n",
            "7\n",
            "406\n",
            "28\n",
            "7\n",
            "490\n",
            "201\n",
            "5\n",
            "3\n",
            "['vier', 'footballspieler', 'in', 'schwarz', 'tackeln', 'im', 'regen', 'einen', 'spieler', 'der', 'gegnerischen', 'mannschaft', 'in', 'weiß', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "110\n",
            "192\n",
            "215\n",
            "6\n",
            "26\n",
            "92\n",
            "6\n",
            "7\n",
            "559\n",
            "15\n",
            "46\n",
            "6\n",
            "25\n",
            "10\n",
            "546\n",
            "7\n",
            "72\n",
            "6\n",
            "25\n",
            "5\n",
            "3\n",
            "['ein', 'runner', 'versucht', ',', 'extra-yards', 'zu', 'machen', 'während', 'er', 'von', 'zwei', 'tacklern', 'zu', 'boden', 'gebracht', 'wird', '.']\n",
            "Encoder output torch.Size([1, 19, 256])\n",
            "4\n",
            "123\n",
            "237\n",
            "904\n",
            "18\n",
            "497\n",
            "0\n",
            "28\n",
            "191\n",
            "0\n",
            "10\n",
            "191\n",
            "852\n",
            "49\n",
            "16\n",
            "0\n",
            "5\n",
            "3\n",
            "['der', 'basketballspieler', 'im', 'weißen', 'trikot', 'mit', 'der', 'nummer', '55', 'deckt', 'den', 'spieler', 'im', 'schwarzen', 'trikot', 'mit', 'der', 'nummer', '10.']\n",
            "Encoder output torch.Size([1, 21, 256])\n",
            "7\n",
            "224\n",
            "105\n",
            "6\n",
            "7\n",
            "448\n",
            "0\n",
            "495\n",
            "3027\n",
            "7\n",
            "448\n",
            "0\n",
            "13\n",
            "7\n",
            "448\n",
            "0\n",
            "105\n",
            "6\n",
            "7\n",
            "448\n",
            "0\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'telefoniert', 'im', 'freien', 'mit', 'dem', 'handy', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "10\n",
            "119\n",
            "8\n",
            "7\n",
            "349\n",
            "57\n",
            "5\n",
            "3\n",
            "['professionelle', 'baseballspieler', 'beobachten', 'beim', 'all-star', 'game', 'einen', 'gegnerischen', 'batter', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "0\n",
            "188\n",
            "215\n",
            "173\n",
            "4\n",
            "0\n",
            "192\n",
            "105\n",
            "5\n",
            "3\n",
            "['ein', 'offroad-biker', 'fährt', 'im', 'herbst', 'durch', 'eine', 'steile', 'kurve', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "2465\n",
            "648\n",
            "241\n",
            "4\n",
            "278\n",
            "86\n",
            "276\n",
            "60\n",
            "7\n",
            "1118\n",
            "5\n",
            "3\n",
            "['3', 'basketballspieler', 'kämpfen', 'um', 'den', 'ball', ',', 'einer', 'in', 'einem', 'roten', 'trikot', 'versucht', ',', 'einem', 'in', 'einem', 'weißen', 'trikot', 'den', 'ball', 'wegzunehmen', '.']\n",
            "Encoder output torch.Size([1, 25, 256])\n",
            "681\n",
            "224\n",
            "215\n",
            "17\n",
            "658\n",
            "54\n",
            "7\n",
            "68\n",
            "6\n",
            "4\n",
            "31\n",
            "68\n",
            "15\n",
            "260\n",
            "18\n",
            "818\n",
            "7\n",
            "68\n",
            "6\n",
            "4\n",
            "25\n",
            "231\n",
            "5\n",
            "3\n",
            "['ein', 'junge', 'greift', 'sich', 'ans', 'bein', 'während', 'er', 'in', 'die', 'luft', 'springt', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "34\n",
            "1037\n",
            "69\n",
            "7\n",
            "103\n",
            "28\n",
            "27\n",
            "729\n",
            "5\n",
            "3\n",
            "['zwei', 'kinder', 'in', 'gestreiften', 'sweatern', 'und', 'schwarzen', 'hosen', 'rangeln', 'im', 'freien', 'neben', 'einem', 'spielplatz', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "16\n",
            "63\n",
            "22\n",
            "194\n",
            "26\n",
            "11\n",
            "26\n",
            "147\n",
            "15\n",
            "325\n",
            "57\n",
            "71\n",
            "18\n",
            "4\n",
            "435\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'mit', 'sonnenbrille', 'fährt', 'auf', 'einem', 'roller', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "4\n",
            "9\n",
            "22\n",
            "217\n",
            "78\n",
            "4\n",
            "686\n",
            "5\n",
            "3\n",
            "['ein', 'kleiner', 'junge', 'in', 'baseballmontur', 'holt', 'mit', 'einem', 'schläger', 'hinter', 'seinem', 'kopf', 'in', 'richtung', 'eines', 'vor', 'ihm', 'montierten', 'baseballs', 'aus', '.']\n",
            "Encoder output torch.Size([1, 23, 256])\n",
            "4\n",
            "53\n",
            "34\n",
            "6\n",
            "2300\n",
            "5376\n",
            "1245\n",
            "147\n",
            "13\n",
            "27\n",
            "172\n",
            "93\n",
            "4\n",
            "1535\n",
            "316\n",
            "240\n",
            "6\n",
            "43\n",
            "12\n",
            "4\n",
            "597\n",
            "12\n",
            "0\n",
            "5\n",
            "3\n",
            "['sechs', 'männer', 'sitzen', 'auf', 'einem', 'acker', 'mit', 'holzkisten', '.']\n",
            "Encoder output torch.Size([1, 11, 256])\n",
            "457\n",
            "30\n",
            "32\n",
            "8\n",
            "4\n",
            "377\n",
            "350\n",
            "13\n",
            "377\n",
            "5\n",
            "3\n",
            "['ein', 'brauner', 'hund', 'hebt', 'einen', 'zweig', 'von', 'einer', 'steinernen', 'oberfläche', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "61\n",
            "35\n",
            "10\n",
            "779\n",
            "51\n",
            "4\n",
            "166\n",
            "230\n",
            "5\n",
            "3\n",
            "['das', 'ist', 'ein', 'gelb', 'gekleideter', 'mann', ',', 'der', 'ein', 'braunes', 'pferd', 'an', 'der', 'leine', 'hält', '.']\n",
            "Encoder output torch.Size([1, 18, 256])\n",
            "209\n",
            "10\n",
            "4\n",
            "9\n",
            "22\n",
            "62\n",
            "15\n",
            "61\n",
            "10\n",
            "45\n",
            "4\n",
            "61\n",
            "198\n",
            "5\n",
            "3\n",
            "['ein', 'mann', 'in', 'einem', 'weißen', 'shirt', 'und', 'einer', 'schürze', 'zerlegt', 'einen', 'vogel', '.']\n",
            "Encoder output torch.Size([1, 15, 256])\n",
            "4\n",
            "9\n",
            "6\n",
            "4\n",
            "25\n",
            "23\n",
            "11\n",
            "21\n",
            "502\n",
            "502\n",
            "10\n",
            "195\n",
            "4\n",
            "625\n",
            "5\n",
            "3\n",
            "['eine', 'hispanische', 'frau', 'kocht', 'im', 'freien', 'in', 'einem', 'wok', '.']\n",
            "Encoder output torch.Size([1, 12, 256])\n",
            "4\n",
            "14\n",
            "6\n",
            "4\n",
            "1758\n",
            "10\n",
            "461\n",
            "20\n",
            "21\n",
            "253\n",
            "253\n",
            "275\n",
            "5\n",
            "3\n",
            "['marathonläuferinnen', 'laufen', 'auf', 'einer', 'städtischen', 'straße', 'während', 'andere', 'personen', 'um', 'sie', 'herum', 'stehen', '.']\n",
            "Encoder output torch.Size([1, 16, 256])\n",
            "0\n",
            "17\n",
            "41\n",
            "8\n",
            "4\n",
            "101\n",
            "39\n",
            "28\n",
            "19\n",
            "17\n",
            "36\n",
            "83\n",
            "5\n",
            "3\n",
            "['asiatische', 'frau', 'trägt', 'einen', 'sonnenhut', 'beim', 'fahrradfahren', '.']\n",
            "Encoder output torch.Size([1, 10, 256])\n",
            "106\n",
            "14\n",
            "151\n",
            "4\n",
            "3725\n",
            "78\n",
            "4\n",
            "99\n",
            "5\n",
            "3\n",
            "['ein', 'paar', 'kinder', 'sind', 'im', 'freien', 'und', 'spielen', 'auf', 'dem', 'boden', 'bei', 'zwei', 'bäumen', '.']\n",
            "Encoder output torch.Size([1, 17, 256])\n",
            "4\n",
            "154\n",
            "63\n",
            "57\n",
            "8\n",
            "7\n",
            "185\n",
            "13\n",
            "16\n",
            "250\n",
            "5\n",
            "3\n",
            "['ein', 'älterer', 'mann', 'spielt', 'ein', 'videospiel', '.']\n",
            "Encoder output torch.Size([1, 9, 256])\n",
            "21\n",
            "115\n",
            "9\n",
            "10\n",
            "37\n",
            "4\n",
            "784\n",
            "135\n",
            "5\n",
            "3\n",
            "['ein', 'mädchen', 'an', 'einer', 'küste', 'mit', 'einem', 'berg', 'im', 'hintergrund', '.']\n",
            "Encoder output torch.Size([1, 13, 256])\n",
            "4\n",
            "33\n",
            "8\n",
            "4\n",
            "514\n",
            "13\n",
            "4\n",
            "221\n",
            "6\n",
            "7\n",
            "98\n",
            "5\n",
            "3\n",
            "BLEU score = 33.10\n"
          ]
        }
      ]
    }
  ]
}